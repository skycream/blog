"""ë…¼ë¬¸ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ëª¨ë“ˆ"""
import re
from typing import List, Dict, Tuple, Optional
from collections import defaultdict


class PaperClassifier:
    """ê·œì¹™ ê¸°ë°˜ + AI ë³´ì¡° ë…¼ë¬¸ ë¶„ë¥˜"""

    # ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ì‚¬ì „
    CATEGORY_KEYWORDS = {
        'cause': {
            'keywords': [
                'pathophysiology', 'etiology', 'mechanism', 'risk factor', 'cause',
                'pathogenesis', 'origin', 'predisposing', 'susceptibility', 'associated with',
                'correlation', 'relationship between', 'underlying', 'development of'
            ],
            'weight': 1.0,
            'korean_name': 'ì›ì¸',
            'description': 'ì§ˆí™˜ì˜ ì›ì¸, ë°œìƒ ê¸°ì „, ìœ„í—˜ ìš”ì¸'
        },
        'treatment': {
            'keywords': [
                'treatment', 'therapy', 'drug', 'medication', 'pharmaceutical',
                'PPI', 'proton pump inhibitor', 'H2 blocker', 'antacid', 'surgery',
                'surgical', 'laparoscopic', 'fundoplication', 'intervention',
                'pharmacological', 'therapeutic', 'efficacy', 'effectiveness'
            ],
            'weight': 1.0,
            'korean_name': 'ì¹˜ë£Œ',
            'description': 'ì•½ë¬¼ì¹˜ë£Œ, ìˆ˜ìˆ , ì˜í•™ì  ê°œì…'
        },
        'diet': {
            'keywords': [
                'diet', 'dietary', 'food', 'nutrition', 'nutritional', 'meal',
                'eating', 'beverage', 'caffeine', 'coffee', 'alcohol', 'spicy',
                'fatty food', 'citrus', 'chocolate', 'tomato', 'intake',
                'consumption', 'calorie', 'fiber', 'vegetable', 'fruit'
            ],
            'weight': 1.2,  # ì‹ì´ í‚¤ì›Œë“œì— ì•½ê°„ ë” ê°€ì¤‘ì¹˜
            'korean_name': 'ì‹ì´ìš”ë²•',
            'description': 'ìŒì‹, ì˜ì–‘, ì‹ë‹¨ ê´€ë ¨'
        },
        'lifestyle': {
            'keywords': [
                'lifestyle', 'exercise', 'physical activity', 'sleep', 'sleeping',
                'smoking', 'tobacco', 'weight', 'obesity', 'BMI', 'body mass',
                'stress', 'anxiety', 'posture', 'position', 'bed elevation',
                'behavior', 'behavioural', 'habit', 'sedentary'
            ],
            'weight': 1.0,
            'korean_name': 'ìƒí™œìŠµê´€',
            'description': 'ìš´ë™, ìˆ˜ë©´, ì²´ì¤‘, ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬'
        },
        'prevention': {
            'keywords': [
                'prevention', 'preventive', 'protective', 'prophylaxis', 'prophylactic',
                'risk reduction', 'avoidance', 'screening', 'early detection',
                'lifestyle modification', 'health promotion'
            ],
            'weight': 0.9,
            'korean_name': 'ì˜ˆë°©',
            'description': 'ì˜ˆë°©ë²•, ìœ„í—˜ ê°ì†Œ'
        },
        'complications': {
            'keywords': [
                'complication', 'barrett', 'esophageal cancer', 'adenocarcinoma',
                'stricture', 'erosive', 'ulcer', 'bleeding', 'perforation',
                'aspiration', 'respiratory', 'dental erosion', 'laryngitis',
                'progression', 'outcome', 'prognosis'
            ],
            'weight': 1.0,
            'korean_name': 'í•©ë³‘ì¦',
            'description': 'í•©ë³‘ì¦, ì˜ˆí›„, ì§„í–‰'
        }
    }

    # ë¶„ë¥˜ ì‹ ë¢°ë„ ì„ê³„ê°’
    HIGH_CONFIDENCE_THRESHOLD = 0.7
    LOW_CONFIDENCE_THRESHOLD = 0.3

    def __init__(self, anthropic_client=None):
        """
        Args:
            anthropic_client: Anthropic API í´ë¼ì´ì–¸íŠ¸ (AI ë¶„ë¥˜ìš©)
        """
        self.anthropic_client = anthropic_client
        self._compile_patterns()

    def _compile_patterns(self):
        """ì •ê·œí‘œí˜„ì‹ íŒ¨í„´ ë¯¸ë¦¬ ì»´íŒŒì¼"""
        self.patterns = {}
        for category, config in self.CATEGORY_KEYWORDS.items():
            # í‚¤ì›Œë“œë¥¼ ì •ê·œí‘œí˜„ì‹ íŒ¨í„´ìœ¼ë¡œ ë³€í™˜ (ë‹¨ì–´ ê²½ê³„ í¬í•¨)
            pattern_str = '|'.join(
                r'\b' + re.escape(kw) + r'\b'
                for kw in config['keywords']
            )
            self.patterns[category] = re.compile(pattern_str, re.IGNORECASE)

    def classify_papers(self, papers: List[Dict]) -> Dict[str, List[Dict]]:
        """
        ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜

        Args:
            papers: ë…¼ë¬¸ ì •ë³´ ë¦¬ìŠ¤íŠ¸

        Returns:
            ì¹´í…Œê³ ë¦¬ë³„ ë…¼ë¬¸ ë”•ì…”ë„ˆë¦¬
        """
        print("\nğŸ“Š ë…¼ë¬¸ ë¶„ë¥˜ ì¤‘...")

        categorized = defaultdict(list)
        low_confidence_papers = []

        for paper in papers:
            category, confidence = self._rule_based_classify(paper)

            if confidence >= self.LOW_CONFIDENCE_THRESHOLD:
                paper['category'] = category
                paper['category_confidence'] = confidence
                categorized[category].append(paper)
            else:
                low_confidence_papers.append(paper)

        # ë‚®ì€ ì‹ ë¢°ë„ ë…¼ë¬¸ ì²˜ë¦¬
        if low_confidence_papers:
            print(f"  âš ï¸ ë¶„ë¥˜ê°€ ì• ë§¤í•œ ë…¼ë¬¸ {len(low_confidence_papers)}ê°œ")

            if self.anthropic_client and len(low_confidence_papers) <= 20:
                # AI ë¶„ë¥˜ ì‹œë„
                ai_results = self._ai_classify(low_confidence_papers)
                for paper, category in zip(low_confidence_papers, ai_results):
                    paper['category'] = category
                    paper['category_confidence'] = 0.5  # AI ë¶„ë¥˜ëŠ” ì¤‘ê°„ ì‹ ë¢°ë„
                    categorized[category].append(paper)
            else:
                # ê¸°ë³¸ ì¹´í…Œê³ ë¦¬(general)ë¡œ ë¶„ë¥˜
                for paper in low_confidence_papers:
                    paper['category'] = 'general'
                    paper['category_confidence'] = 0.2
                    categorized['general'].append(paper)

        # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        print("\nâœ“ ë¶„ë¥˜ ì™„ë£Œ:")
        for category, category_papers in sorted(categorized.items()):
            config = self.CATEGORY_KEYWORDS.get(category, {'korean_name': 'ê¸°íƒ€'})
            print(f"  - {config.get('korean_name', category)}: {len(category_papers)}ê°œ")

        return dict(categorized)

    def _rule_based_classify(self, paper: Dict) -> Tuple[str, float]:
        """
        ê·œì¹™ ê¸°ë°˜ ë…¼ë¬¸ ë¶„ë¥˜

        Args:
            paper: ë…¼ë¬¸ ì •ë³´

        Returns:
            (ì¹´í…Œê³ ë¦¬, ì‹ ë¢°ë„ ì ìˆ˜)
        """
        title = paper.get('title', '').lower()
        abstract = paper.get('abstract', '').lower()
        text = f"{title} {title} {abstract}"  # ì œëª©ì— 2ë°° ê°€ì¤‘ì¹˜

        scores = {}

        for category, config in self.CATEGORY_KEYWORDS.items():
            pattern = self.patterns[category]
            matches = pattern.findall(text)

            # ê¸°ë³¸ ì ìˆ˜: ë§¤ì¹­ëœ í‚¤ì›Œë“œ ê°œìˆ˜ * ê°€ì¤‘ì¹˜
            base_score = len(matches) * config['weight']

            # ì œëª©ì—ì„œ ë§¤ì¹­ë˜ë©´ ì¶”ê°€ ì ìˆ˜
            title_matches = pattern.findall(title)
            title_bonus = len(title_matches) * 0.5

            scores[category] = base_score + title_bonus

        if not scores or max(scores.values()) == 0:
            return 'general', 0.0

        # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì¹´í…Œê³ ë¦¬ ì„ íƒ
        best_category = max(scores, key=scores.get)
        max_score = scores[best_category]

        # ì‹ ë¢°ë„ ê³„ì‚° (ì •ê·œí™”)
        total_score = sum(scores.values())
        confidence = max_score / total_score if total_score > 0 else 0.0

        return best_category, confidence

    def _ai_classify(self, papers: List[Dict]) -> List[str]:
        """
        Claude AIë¥¼ ì‚¬ìš©í•œ ë…¼ë¬¸ ë¶„ë¥˜ (ë°°ì¹˜ ì²˜ë¦¬)

        Args:
            papers: ë¶„ë¥˜í•  ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸

        Returns:
            ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸
        """
        if not self.anthropic_client:
            return ['general'] * len(papers)

        try:
            # ë…¼ë¬¸ ì •ë³´ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            papers_text = ""
            for i, paper in enumerate(papers, 1):
                papers_text += f"\n[{i}] {paper.get('title', 'No title')}\n"
                papers_text += f"Abstract: {paper.get('abstract', 'No abstract')[:500]}...\n"

            categories_list = list(self.CATEGORY_KEYWORDS.keys())
            categories_desc = "\n".join([
                f"- {cat}: {config['description']}"
                for cat, config in self.CATEGORY_KEYWORDS.items()
            ])

            prompt = f"""ë‹¤ìŒ ë…¼ë¬¸ë“¤ì„ ì•„ë˜ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.

ì¹´í…Œê³ ë¦¬:
{categories_desc}
- general: ìœ„ ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ê²½ìš°

ë…¼ë¬¸ë“¤:
{papers_text}

ê° ë…¼ë¬¸ ë²ˆí˜¸ì— ëŒ€í•´ ê°€ì¥ ì í•©í•œ ì¹´í…Œê³ ë¦¬ë¥¼ í•œ ì¤„ì— í•˜ë‚˜ì”© ì¶œë ¥í•´ì£¼ì„¸ìš”.
í˜•ì‹: [ë²ˆí˜¸] ì¹´í…Œê³ ë¦¬
ì˜ˆì‹œ:
[1] treatment
[2] diet
[3] cause"""

            response = self.anthropic_client.messages.create(
                model="claude-sonnet-4-5-20250929",
                max_tokens=500,
                messages=[{"role": "user", "content": prompt}]
            )

            result_text = response.content[0].text

            # ê²°ê³¼ íŒŒì‹±
            results = []
            for line in result_text.strip().split('\n'):
                for cat in categories_list + ['general']:
                    if cat in line.lower():
                        results.append(cat)
                        break
                else:
                    results.append('general')

            # ë…¼ë¬¸ ê°œìˆ˜ì™€ ê²°ê³¼ ê°œìˆ˜ê°€ ë§ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
            while len(results) < len(papers):
                results.append('general')

            return results[:len(papers)]

        except Exception as e:
            print(f"  âš ï¸ AI ë¶„ë¥˜ ì‹¤íŒ¨: {str(e)}")
            return ['general'] * len(papers)

    def get_category_stats(self, categorized_papers: Dict[str, List[Dict]]) -> Dict:
        """
        ì¹´í…Œê³ ë¦¬ë³„ í†µê³„ ì •ë³´ ë°˜í™˜

        Args:
            categorized_papers: ë¶„ë¥˜ëœ ë…¼ë¬¸ ë”•ì…”ë„ˆë¦¬

        Returns:
            í†µê³„ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        stats = {
            'total': sum(len(papers) for papers in categorized_papers.values()),
            'categories': {}
        }

        for category, papers in categorized_papers.items():
            config = self.CATEGORY_KEYWORDS.get(category, {'korean_name': category})
            avg_confidence = sum(p.get('category_confidence', 0) for p in papers) / len(papers) if papers else 0

            stats['categories'][category] = {
                'count': len(papers),
                'korean_name': config.get('korean_name', category),
                'average_confidence': round(avg_confidence, 2)
            }

        return stats

    @classmethod
    def get_available_categories(cls) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬ ëª©ë¡ ë°˜í™˜"""
        return list(cls.CATEGORY_KEYWORDS.keys())


def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    # í…ŒìŠ¤íŠ¸ ë…¼ë¬¸ ë°ì´í„°
    test_papers = [
        {
            'title': 'Proton pump inhibitors for treatment of GERD',
            'abstract': 'This study evaluated the efficacy of PPI therapy in patients with gastroesophageal reflux disease.'
        },
        {
            'title': 'Dietary factors and gastroesophageal reflux',
            'abstract': 'We investigated the relationship between food intake, caffeine consumption and reflux symptoms.'
        },
        {
            'title': 'Pathophysiology of GERD: mechanisms and risk factors',
            'abstract': 'The etiology of GERD involves multiple pathogenic mechanisms including lower esophageal sphincter dysfunction.'
        },
        {
            'title': 'Lifestyle modifications for reflux management',
            'abstract': 'Weight loss, smoking cessation, and sleep position changes can improve GERD symptoms.'
        },
        {
            'title': 'Barrett esophagus and esophageal adenocarcinoma risk',
            'abstract': 'Long-term complications of GERD include progression to Barrett esophagus and cancer.'
        }
    ]

    classifier = PaperClassifier()
    categorized = classifier.classify_papers(test_papers)

    print("\n" + "="*60)
    print("ë¶„ë¥˜ ê²°ê³¼:")
    print("="*60)

    for category, papers in categorized.items():
        config = classifier.CATEGORY_KEYWORDS.get(category, {'korean_name': category})
        print(f"\nğŸ“ {config.get('korean_name', category)} ({category}):")
        for paper in papers:
            print(f"  - {paper['title'][:60]}...")
            print(f"    ì‹ ë¢°ë„: {paper.get('category_confidence', 0):.2f}")

    stats = classifier.get_category_stats(categorized)
    print(f"\nğŸ“Š ì´ {stats['total']}ê°œ ë…¼ë¬¸ ë¶„ë¥˜ ì™„ë£Œ")


if __name__ == "__main__":
    main()
