"""
LLM ê¸°ë°˜ ë…¼ë¬¸ ë¶„ì„ ëª¨ë“ˆ
- ë…¼ë¬¸ ì „ë¬¸/ì´ˆë¡ì„ êµ¬ì¡°í™”ëœ ì •ë³´ë¡œ ì¶”ì¶œ
- Claude CLIì—ì„œ ì‚¬ìš©í•˜ë„ë¡ ì„¤ê³„
"""

import json
from typing import Dict, List
from datetime import datetime


# ë…¼ë¬¸ ë¶„ì„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
PAPER_ANALYSIS_PROMPT = """
ë‹¹ì‹ ì€ ì˜í•™ ë…¼ë¬¸ ë¶„ì„ ì „ë¬¸ê°€ìž…ë‹ˆë‹¤. ì•„ëž˜ ë…¼ë¬¸ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ êµ¬ì¡°í™”ëœ JSONìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”.

## ë…¼ë¬¸ ì •ë³´
- ì œëª©: {title}
- ì €ë„: {journal} ({year})
- PMID: {pmid}

## ì´ˆë¡/ë³¸ë¬¸
{content}

## ë¶„ì„ ìš”ì²­
ìœ„ ë…¼ë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”:

```json
{{
  "pmid": "{pmid}",
  "ì—°êµ¬ìœ í˜•": "RCT/ì½”í˜¸íŠ¸/ë©”íƒ€ë¶„ì„/ë¦¬ë·°/ì‚¬ë¡€ì—°êµ¬ ì¤‘ íƒ1",
  "ì—°êµ¬ëŒ€ìƒ": {{
    "ì¸ì›": "Nëª… (ìˆ«ìž ë˜ëŠ” 'ëª…ì‹œì•ˆë¨')",
    "íŠ¹ì„±": "ì—°ë ¹ëŒ€, ì„±ë³„, íŠ¹ì´ì‚¬í•­ ë“±"
  }},
  "ì—°êµ¬ë°©ë²•": "ì—°êµ¬ ì„¤ê³„ ë° ë°©ë²•ë¡  ìš”ì•½ (100ìž ì´ë‚´)",
  "ì£¼ìš”ê²°ê³¼": {{
    "íš¨ê³¼í¬ê¸°": "OR, RR, HR, % ë“± êµ¬ì²´ì  ìˆ˜ì¹˜ (ìžˆëŠ” ê²½ìš°)",
    "í†µê³„ì ìœ ì˜ì„±": "pê°’ ë˜ëŠ” 95% CI (ìžˆëŠ” ê²½ìš°)",
    "ê²°ê³¼ìš”ì•½": "í•µì‹¬ ë°œê²¬ (200ìž ì´ë‚´)"
  }},
  "í•µì‹¬ê²°ë¡ ": "ì´ ì—°êµ¬ì˜ í•µì‹¬ ê²°ë¡ ê³¼ ì˜ë¯¸ (500ìž ì´ë‚´, í•œê¸€ë¡œ)",
  "ì‹¤ìš©ì ì‹œì‚¬ì ": "ì¼ë°˜ì¸ì´ ì•Œì•„ì•¼ í•  ì‹¤ì²œ ê°€ëŠ¥í•œ ì¡°ì–¸ (300ìž ì´ë‚´, í•œê¸€ë¡œ)",
  "í•œê³„ì ": "ì—°êµ¬ì˜ í•œê³„ (ìžˆëŠ” ê²½ìš°, 100ìž ì´ë‚´)",
  "ì‹ ë¢°ë„": "ìƒ/ì¤‘/í•˜ (ì—°êµ¬ ì„¤ê³„ì™€ í‘œë³¸ í¬ê¸° ê¸°ë°˜)"
}}
```

JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ í•„ìš” ì—†ìŠµë‹ˆë‹¤.
"""


def create_analysis_request(papers: List[Dict]) -> Dict:
    """
    ë…¼ë¬¸ ëª©ë¡ì„ Claude CLI ë¶„ì„ìš© ìš”ì²­ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    """
    analysis_requests = []

    for paper in papers:
        # ë¶„ì„í•  ë‚´ìš© ê²°ì • (ì „ë¬¸ > ì´ˆë¡)
        if paper.get('conclusion') and len(paper.get('conclusion', '')) > 100:
            content = f"[ê²°ë¡  ì„¹ì…˜]\n{paper['conclusion']}"
            if paper.get('results'):
                content += f"\n\n[ê²°ê³¼ ì„¹ì…˜]\n{paper['results'][:2000]}"
        elif paper.get('abstract'):
            content = f"[ì´ˆë¡]\n{paper['abstract']}"
        else:
            content = "ë‚´ìš© ì—†ìŒ"

        request = {
            "pmid": paper.get('pmid', ''),
            "title": paper.get('title', ''),
            "journal": paper.get('journal', ''),
            "year": paper.get('year', ''),
            "authors": paper.get('authors', [])[:3],
            "has_fulltext": paper.get('has_fulltext', False),
            "content_for_analysis": content,
            "prompt": PAPER_ANALYSIS_PROMPT.format(
                title=paper.get('title', ''),
                journal=paper.get('journal', ''),
                year=paper.get('year', ''),
                pmid=paper.get('pmid', ''),
                content=content
            )
        }
        analysis_requests.append(request)

    return {
        "created_at": datetime.now().isoformat(),
        "total_papers": len(papers),
        "fulltext_count": sum(1 for p in papers if p.get('has_fulltext')),
        "papers": analysis_requests
    }


def create_batch_analysis_prompt(papers: List[Dict], keyword: str, topics: List[str] = None) -> str:
    """
    ì—¬ëŸ¬ ë…¼ë¬¸ì„ í•œë²ˆì— ë¶„ì„í•˜ëŠ” ë°°ì¹˜ í”„ë¡¬í”„íŠ¸ ìƒì„±
    - ê´€ë ¨ì„± ì ìˆ˜ í¬í•¨ (75ì  ì´ìƒë§Œ ì±„íƒ)
    """
    papers_text = ""

    for i, paper in enumerate(papers, 1):
        # ë¶„ì„í•  ë‚´ìš© ê²°ì •
        if paper.get('conclusion') and len(paper.get('conclusion', '')) > 100:
            content = paper['conclusion'][:1500]
            source = "ì „ë¬¸-ê²°ë¡ "
        elif paper.get('abstract'):
            content = paper['abstract']
            source = "ì´ˆë¡"
        else:
            content = "ë‚´ìš© ì—†ìŒ"
            source = "ì—†ìŒ"

        papers_text += f"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ðŸ“„ ë…¼ë¬¸ #{i}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì œëª©: {paper.get('title', 'N/A')}
ì €ë„: {paper.get('journal', 'N/A')} ({paper.get('year', 'N/A')})
PMID: {paper.get('pmid', 'N/A')}
ì¶œì²˜: {source}

ë‚´ìš©:
{content}

"""

    # í† í”½ ëª©ë¡ ë¬¸ìžì—´
    topics_str = ", ".join(topics) if topics else "ì—†ìŒ"

    prompt = f"""
# ë…¼ë¬¸ ë¶„ì„ ìš”ì²­

## ë©”ì¸ í‚¤ì›Œë“œ: {keyword}
## ì„ íƒëœ í† í”½(ë¶€ì£¼ì œ): {topics_str}
## ì´ ë…¼ë¬¸ ìˆ˜: {len(papers)}íŽ¸

ë‹¹ì‹ ì€ ì˜í•™ ë…¼ë¬¸ ë¶„ì„ ì „ë¬¸ê°€ìž…ë‹ˆë‹¤.
ì•„ëž˜ {len(papers)}íŽ¸ì˜ ë…¼ë¬¸ì„ ê°ê° ë¶„ì„í•˜ê³ , **ê´€ë ¨ì„± ì ìˆ˜**ë¥¼ ë§¤ê²¨ì£¼ì„¸ìš”.

{papers_text}

## ê´€ë ¨ì„± ì ìˆ˜ ê¸°ì¤€ (100ì  ë§Œì )

**í‚¤ì›Œë“œê°€ ì¤‘ì‹¬ì´ê³ , í† í”½ì€ ë¶€ì£¼ì œìž…ë‹ˆë‹¤.**

1. **í‚¤ì›Œë“œ ê´€ë ¨ì„± (80ì  ë§Œì )**
   - ë…¼ë¬¸ì´ ë©”ì¸ í‚¤ì›Œë“œ '{keyword}'ë¥¼ ì§ì ‘ ë‹¤ë£¨ë©´: 80ì 
   - í‚¤ì›Œë“œì™€ ë°€ì ‘í•˜ê²Œ ê´€ë ¨ë˜ë©´: 60-79ì 
   - ê°„ì ‘ì ìœ¼ë¡œë§Œ ê´€ë ¨ë˜ë©´: 40-59ì 
   - ê±°ì˜ ê´€ë ¨ ì—†ìœ¼ë©´: 0-39ì 

2. **í† í”½ ê´€ë ¨ì„± (20ì  ë§Œì )**
   - ì„ íƒëœ í† í”½ ì¤‘ í•˜ë‚˜ ì´ìƒì„ êµ¬ì²´ì ìœ¼ë¡œ ë‹¤ë£¨ë©´: 15-20ì 
   - í† í”½ê³¼ ì¼ë¶€ ê´€ë ¨ë˜ë©´: 5-14ì 
   - í† í”½ê³¼ ë¬´ê´€í•˜ë©´: 0ì 

**75ì  ì´ìƒì¸ ë…¼ë¬¸ë§Œ ì±„íƒë©ë‹ˆë‹¤.**

## ì¶œë ¥ í˜•ì‹

ê° ë…¼ë¬¸ì— ëŒ€í•´ ë‹¤ìŒ êµ¬ì¡°ì˜ JSONì„ ìƒì„±í•˜ê³ , ì „ì²´ë¥¼ ë°°ì—´ë¡œ ë¬¶ì–´ì£¼ì„¸ìš”:

```json
[
  {{
    "ë²ˆí˜¸": 1,
    "pmid": "12345678",
    "ê´€ë ¨ì„±ì ìˆ˜": 85,
    "ì ìˆ˜ê·¼ê±°": "í‚¤ì›Œë“œ 80ì (ì§ì ‘ ë‹¤ë£¸) + í† í”½ 5ì (ì‹ì´ ê´€ë ¨ ì–¸ê¸‰)",
    "ì±„íƒì—¬ë¶€": true,
    "ì œëª©_í•œê¸€": "ë…¼ë¬¸ ì œëª© í•œê¸€ ë²ˆì—­",
    "ì—°êµ¬ìœ í˜•": "RCT/ì½”í˜¸íŠ¸/ë©”íƒ€ë¶„ì„/ë¦¬ë·°/ì‚¬ë¡€ì—°êµ¬/ì‹¤í—˜ì—°êµ¬",
    "ì—°êµ¬ëŒ€ìƒ": "ëŒ€ìƒìž ìˆ˜ì™€ íŠ¹ì„± (ì˜ˆ: ì„±ì¸ 1,234ëª…, í‰ê·  45ì„¸)",
    "ì£¼ìš”ê²°ê³¼": "í•µì‹¬ ë°œê²¬ê³¼ íš¨ê³¼ í¬ê¸° (ì˜ˆ: ìœ„í—˜ë„ 40% ê°ì†Œ, OR=0.6)",
    "í•µì‹¬ê²°ë¡ ": "ì´ ì—°êµ¬ì˜ ê²°ë¡ ê³¼ ì˜ë¯¸ë¥¼ ìƒì„¸ížˆ ì„¤ëª… (ìµœëŒ€ 500ìž, í•œê¸€)",
    "ì‹¤ìš©ì ì‹œì‚¬ì ": "ì¼ë°˜ì¸ì´ ì‹¤ì²œí•  ìˆ˜ ìžˆëŠ” êµ¬ì²´ì  ì¡°ì–¸ (ìµœëŒ€ 300ìž, í•œê¸€)",
    "ì‹ ë¢°ë„": "ìƒ/ì¤‘/í•˜",
    "ì›ë¬¸_ì´ˆë¡": "ì±„íƒëœ ë…¼ë¬¸ë§Œ! ì´ˆë¡ ì›ë¬¸ ì „ì²´ë¥¼ ê·¸ëŒ€ë¡œ ë³µì‚¬",
    "ì›ë¬¸_ê²°ë¡ ": "ì±„íƒëœ ë…¼ë¬¸ë§Œ! ê²°ë¡  ì›ë¬¸ ì „ì²´ë¥¼ ê·¸ëŒ€ë¡œ ë³µì‚¬ (ìžˆëŠ” ê²½ìš°)"
  }},
  ...
]
```

## ì¤‘ìš” ì§€ì¹¨
1. **ê´€ë ¨ì„±ì ìˆ˜ 75ì  ë¯¸ë§Œì´ë©´ ì±„íƒì—¬ë¶€ë¥¼ falseë¡œ ì„¤ì •**
2. ì±„íƒì—¬ë¶€ê°€ falseì¸ ë…¼ë¬¸: í•µì‹¬ê²°ë¡ , ì‹¤ìš©ì ì‹œì‚¬ì , ì›ë¬¸_ì´ˆë¡, ì›ë¬¸_ê²°ë¡  ëª¨ë‘ "ë¯¸ì±„íƒ"ìœ¼ë¡œ í‘œì‹œ
3. **ì±„íƒì—¬ë¶€ê°€ trueì¸ ë…¼ë¬¸: ì›ë¬¸_ì´ˆë¡ê³¼ ì›ë¬¸_ê²°ë¡ ì„ ë°˜ë“œì‹œ ì›ë¬¸ ê·¸ëŒ€ë¡œ í¬í•¨** (ë¸”ë¡œê·¸ ìž‘ì„± ì‹œ ë””í…Œì¼í•œ ë‚´ìš© ì°¸ì¡°ìš©)
4. ëª¨ë“  ë¶„ì„ ë‚´ìš©ì€ í•œê¸€ë¡œ ìž‘ì„± (ì›ë¬¸ì€ ì˜ì–´ ê·¸ëŒ€ë¡œ)
5. í•µì‹¬ê²°ë¡ ì€ ì¶©ë¶„ížˆ ìƒì„¸í•˜ê²Œ (ìµœëŒ€ 500ìž)
6. ì‹¤ìš©ì ì‹œì‚¬ì ì€ "~í•˜ì„¸ìš”", "~ì´ ì¢‹ìŠµë‹ˆë‹¤" í˜•íƒœì˜ ì‹¤ì²œ ì¡°ì–¸
7. íš¨ê³¼ í¬ê¸°(%, OR, RR ë“±)ê°€ ìžˆìœ¼ë©´ ë°˜ë“œì‹œ í¬í•¨
8. JSON ë°°ì—´ë§Œ ë°˜í™˜í•˜ì„¸ìš”.
"""

    return prompt


def save_for_claude_analysis(papers: List[Dict], keyword: str, output_path: str) -> str:
    """
    Claude CLI ë¶„ì„ì„ ìœ„í•œ íŒŒì¼ ì €ìž¥
    """
    # ë°°ì¹˜ í”„ë¡¬í”„íŠ¸ ìƒì„±
    batch_prompt = create_batch_analysis_prompt(papers, keyword)

    # ì €ìž¥í•  ë°ì´í„°
    data = {
        "keyword": keyword,
        "created_at": datetime.now().isoformat(),
        "total_papers": len(papers),
        "fulltext_count": sum(1 for p in papers if p.get('has_fulltext')),
        "analysis_prompt": batch_prompt,
        "papers_raw": papers
    }

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    return output_path


# ë¶„ì„ ê²°ê³¼ íŒŒì‹±
def parse_analysis_result(json_text: str) -> List[Dict]:
    """
    Claudeê°€ ë°˜í™˜í•œ JSON ë¶„ì„ ê²°ê³¼ íŒŒì‹±
    """
    try:
        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
        start = json_text.find('[')
        end = json_text.rfind(']') + 1
        if start != -1 and end > start:
            json_str = json_text[start:end]
            return json.loads(json_str)
    except json.JSONDecodeError:
        pass

    return []
