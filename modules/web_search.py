"""ì›¹ ê²€ìƒ‰ì„ í†µí•œ ì—°ê´€ í‚¤ì›Œë“œ ì¶”ì¶œ ëª¨ë“ˆ"""
import requests
import urllib.parse
import time
from typing import List, Dict, Optional


class WebSearchKeywordExtractor:
    """Google Autocompleteì™€ DuckDuckGoë¥¼ ì‚¬ìš©í•œ ì—°ê´€ í‚¤ì›Œë“œ ì¶”ì¶œ"""

    def __init__(self, delay: float = 0.5):
        """
        Args:
            delay: API ìš”ì²­ ê°„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
        """
        self.delay = delay
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }

    def extract_related_keywords(self, keyword: str, max_keywords: int = 15) -> List[Dict]:
        """
        ì—¬ëŸ¬ ì†ŒìŠ¤ì—ì„œ ì—°ê´€ í‚¤ì›Œë“œ ì¶”ì¶œ

        Args:
            keyword: ê¸°ë³¸ í‚¤ì›Œë“œ
            max_keywords: ìµœëŒ€ í‚¤ì›Œë“œ ê°œìˆ˜

        Returns:
            ì—°ê´€ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ [{'keyword': str, 'source': str}, ...]
        """
        print(f"\nğŸ” '{keyword}' ì—°ê´€ í‚¤ì›Œë“œ ê²€ìƒ‰ ì¤‘...")

        all_keywords = []
        seen = set()

        # 1. Google Autocomplete
        google_keywords = self._google_autocomplete(keyword)
        for kw in google_keywords:
            if kw.lower() not in seen and kw.lower() != keyword.lower():
                seen.add(kw.lower())
                all_keywords.append({'keyword': kw, 'source': 'google'})

        time.sleep(self.delay)

        # 2. DuckDuckGo Related Topics
        ddg_keywords = self._duckduckgo_related(keyword)
        for kw in ddg_keywords:
            if kw.lower() not in seen and kw.lower() != keyword.lower():
                seen.add(kw.lower())
                all_keywords.append({'keyword': kw, 'source': 'duckduckgo'})

        time.sleep(self.delay)

        # 3. Google Autocomplete with suffixes
        suffixes = ['ì¦ìƒ', 'ì›ì¸', 'ì¹˜ë£Œ', 'ìŒì‹', 'ì•½', 'ìš´ë™', 'symptoms', 'treatment', 'diet', 'cause']
        for suffix in suffixes[:5]:  # ì²˜ìŒ 5ê°œë§Œ ì‹œë„
            suffix_keywords = self._google_autocomplete(f"{keyword} {suffix}")
            for kw in suffix_keywords[:2]:  # ê° suffixë‹¹ 2ê°œë§Œ
                if kw.lower() not in seen:
                    seen.add(kw.lower())
                    all_keywords.append({'keyword': kw, 'source': 'google_extended'})
            time.sleep(self.delay / 2)

        # ê²°ê³¼ ì œí•œ
        result = all_keywords[:max_keywords]
        print(f"âœ“ {len(result)}ê°œì˜ ì—°ê´€ í‚¤ì›Œë“œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

        return result

    def _google_autocomplete(self, keyword: str) -> List[str]:
        """
        Google Autocomplete APIë¥¼ ì‚¬ìš©í•œ í‚¤ì›Œë“œ ì¶”ì¶œ
        (ë¬´ë£Œ ë¹„ê³µì‹ API)
        """
        try:
            encoded = urllib.parse.quote(keyword)
            url = f"https://suggestqueries.google.com/complete/search?client=firefox&q={encoded}"

            response = requests.get(url, headers=self.headers, timeout=10)
            response.raise_for_status()

            data = response.json()
            if isinstance(data, list) and len(data) >= 2:
                suggestions = data[1]
                if isinstance(suggestions, list):
                    return [s for s in suggestions if isinstance(s, str)]

            return []

        except Exception as e:
            print(f"  âš ï¸ Google Autocomplete ì‹¤íŒ¨: {str(e)}")
            return []

    def _duckduckgo_related(self, keyword: str) -> List[str]:
        """
        DuckDuckGo Instant Answer APIë¥¼ ì‚¬ìš©í•œ ì—°ê´€ í‚¤ì›Œë“œ ì¶”ì¶œ
        """
        try:
            encoded = urllib.parse.quote(keyword)
            url = f"https://api.duckduckgo.com/?q={encoded}&format=json&no_redirect=1"

            response = requests.get(url, headers=self.headers, timeout=10)
            response.raise_for_status()

            data = response.json()
            keywords = []

            # Related Topics
            related = data.get('RelatedTopics', [])
            for item in related:
                if isinstance(item, dict):
                    # Direct topic
                    if 'Text' in item:
                        text = item['Text']
                        # ì²« ë²ˆì§¸ ë¬¸ì¥ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
                        first_part = text.split('.')[0].split(',')[0]
                        if len(first_part) < 50:
                            keywords.append(first_part.strip())
                    # Subtopics
                    if 'Topics' in item:
                        for sub in item['Topics'][:3]:
                            if isinstance(sub, dict) and 'Text' in sub:
                                first_part = sub['Text'].split('.')[0].split(',')[0]
                                if len(first_part) < 50:
                                    keywords.append(first_part.strip())

            return keywords[:10]

        except Exception as e:
            print(f"  âš ï¸ DuckDuckGo ì‹¤íŒ¨: {str(e)}")
            return []

    def get_search_queries(self, keyword: str, related_keywords: List[Dict]) -> List[str]:
        """
        ê¸°ë³¸ í‚¤ì›Œë“œì™€ ì—°ê´€ í‚¤ì›Œë“œë¥¼ ì¡°í•©í•˜ì—¬ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±

        Args:
            keyword: ê¸°ë³¸ í‚¤ì›Œë“œ
            related_keywords: ì—°ê´€ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸

        Returns:
            ê²€ìƒ‰ ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸
        """
        queries = [keyword]  # ê¸°ë³¸ í‚¤ì›Œë“œ

        for item in related_keywords:
            kw = item['keyword']
            # ì´ë¯¸ ê¸°ë³¸ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            if keyword.lower() in kw.lower():
                queries.append(kw)
            else:
                # ê¸°ë³¸ í‚¤ì›Œë“œì™€ ì¡°í•©
                queries.append(f"{keyword} {kw}")

        return queries


def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    extractor = WebSearchKeywordExtractor()

    test_keywords = ["ì—­ë¥˜ì„±ì‹ë„ì—¼", "GERD"]

    for keyword in test_keywords:
        print(f"\n{'='*60}")
        print(f"í…ŒìŠ¤íŠ¸: {keyword}")
        print('='*60)

        related = extractor.extract_related_keywords(keyword, max_keywords=10)

        print("\nğŸ“‹ ì—°ê´€ í‚¤ì›Œë“œ:")
        for i, item in enumerate(related, 1):
            print(f"  {i}. {item['keyword']} (ì†ŒìŠ¤: {item['source']})")

        queries = extractor.get_search_queries(keyword, related)
        print("\nğŸ” ìƒì„±ëœ ê²€ìƒ‰ ì¿¼ë¦¬:")
        for i, query in enumerate(queries[:5], 1):
            print(f"  {i}. {query}")


if __name__ == "__main__":
    main()
