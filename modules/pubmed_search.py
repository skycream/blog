"""PubMed ë…¼ë¬¸ ê²€ìƒ‰ ëª¨ë“ˆ"""
import requests
import xml.etree.ElementTree as ET
from typing import List, Dict, Optional
import time


class PubMedSearcher:
    """PubMed APIë¥¼ ì‚¬ìš©í•œ ë…¼ë¬¸ ê²€ìƒ‰"""

    def __init__(self, email: str, api_key: Optional[str] = None):
        """
        Args:
            email: PubMed API ì‚¬ìš©ì„ ìœ„í•œ ì´ë©”ì¼
            api_key: PubMed API í‚¤ (ì„ íƒì‚¬í•­, ìˆìœ¼ë©´ ìš”ì²­ ì œí•œ ì™„í™”)
        """
        self.email = email
        self.api_key = api_key
        self.base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/"

    def search(self, query: str, max_results: int = 12,
               sort_by: str = "relevance", strict: bool = False) -> List[str]:
        """
        PubMedì—ì„œ ë…¼ë¬¸ ê²€ìƒ‰

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            max_results: ìµœëŒ€ ê²°ê³¼ ê°œìˆ˜
            sort_by: ì •ë ¬ ê¸°ì¤€ ("relevance", "pub_date", "cited")
            strict: Trueë©´ ê³ í’ˆì§ˆ ì—°êµ¬ë§Œ, Falseë©´ ë” ë§ì€ ê²°ê³¼

        Returns:
            PubMed ID ë¦¬ìŠ¤íŠ¸
        """
        try:
            # ê²€ìƒ‰ ì¿¼ë¦¬ ìµœì í™”
            search_query = self._optimize_query(query, strict=strict)

            # PubMed API ìš”ì²­
            params = {
                'db': 'pubmed',
                'term': search_query,
                'retmax': max_results,
                'sort': sort_by,
                'retmode': 'xml',
                'email': self.email
            }

            if self.api_key:
                params['api_key'] = self.api_key

            response = requests.get(f"{self.base_url}esearch.fcgi", params=params)
            response.raise_for_status()

            # XML íŒŒì‹±
            root = ET.fromstring(response.content)
            pmids = [id_elem.text for id_elem in root.findall('.//Id')]

            print(f"âœ“ {len(pmids)}ê°œì˜ ë…¼ë¬¸ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            return pmids

        except Exception as e:
            print(f"âœ— PubMed ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []

    def fetch_details(self, pmids: List[str]) -> List[Dict]:
        """
        ë…¼ë¬¸ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°

        Args:
            pmids: PubMed ID ë¦¬ìŠ¤íŠ¸

        Returns:
            ë…¼ë¬¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
        """
        if not pmids:
            return []

        papers = []
        batch_size = 10  # í•œ ë²ˆì— ê°€ì ¸ì˜¬ ë…¼ë¬¸ ê°œìˆ˜

        try:
            for i in range(0, len(pmids), batch_size):
                batch_pmids = pmids[i:i+batch_size]

                # API ìš”ì²­ ì œí•œ ì¤€ìˆ˜
                if i > 0:
                    time.sleep(0.4)  # ì´ˆë‹¹ 3íšŒ ì œí•œ

                # PubMed API ìš”ì²­
                params = {
                    'db': 'pubmed',
                    'id': ','.join(batch_pmids),
                    'retmode': 'xml',
                    'email': self.email
                }

                if self.api_key:
                    params['api_key'] = self.api_key

                response = requests.get(f"{self.base_url}efetch.fcgi", params=params)
                response.raise_for_status()

                # XML íŒŒì‹±
                root = ET.fromstring(response.content)

                # ê° ë…¼ë¬¸ ì •ë³´ íŒŒì‹±
                for article in root.findall('.//PubmedArticle'):
                    paper = self._parse_paper_xml(article)
                    if paper:
                        papers.append(paper)

                print(f"âœ“ {len(papers)}/{len(pmids)} ë…¼ë¬¸ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")

            return papers

        except Exception as e:
            print(f"âœ— ë…¼ë¬¸ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
            return papers

    def _optimize_query(self, query: str, strict: bool = False) -> str:
        """ê²€ìƒ‰ ì¿¼ë¦¬ ìµœì í™”"""
        # ì£¼ ê²€ìƒ‰ì–´ë¥¼ ì œëª©/ì´ˆë¡ì—ì„œ ê²€ìƒ‰
        main_query = f"({query}[Title/Abstract])"

        if strict:
            # ì—„ê²© ëª¨ë“œ: ê³ í’ˆì§ˆ ì—°êµ¬ë§Œ
            filters = [
                "AND (Review[PT] OR Meta-Analysis[PT] OR Randomized Controlled Trial[PT] OR Clinical Trial[PT])",
                "AND (hasabstract[text])",
                "AND (\"last 10 years\"[PDat])"
            ]
        else:
            # ì™„í™” ëª¨ë“œ: ë” ë§ì€ ë…¼ë¬¸ ìˆ˜ì§‘
            filters = [
                "AND (hasabstract[text])",
                "AND (\"last 15 years\"[PDat])",  # 15ë…„ìœ¼ë¡œ í™•ëŒ€
                "AND (humans[MeSH Terms])"  # ì¸ê°„ ëŒ€ìƒ ì—°êµ¬
            ]

        optimized = main_query
        for filter_str in filters:
            optimized += f" {filter_str}"

        return optimized

    def _parse_paper_xml(self, article_elem) -> Optional[Dict]:
        """XML ìš”ì†Œì—ì„œ ë…¼ë¬¸ ì •ë³´ ì¶”ì¶œ"""
        try:
            # PMID
            pmid_elem = article_elem.find('.//PMID')
            pmid = pmid_elem.text if pmid_elem is not None else 'Unknown'

            # ì œëª©
            title_elem = article_elem.find('.//ArticleTitle')
            title = title_elem.text if title_elem is not None else 'No Title'

            # ì €ì
            authors = []
            for author_elem in article_elem.findall('.//Author')[:5]:
                lastname = author_elem.find('LastName')
                initials = author_elem.find('Initials')
                if lastname is not None and initials is not None:
                    authors.append(f"{lastname.text} {initials.text}")

            # ì €ë„
            journal_elem = article_elem.find('.//Journal/Title')
            journal = journal_elem.text if journal_elem is not None else 'Unknown Journal'

            # ì—°ë„
            year_elem = article_elem.find('.//PubDate/Year')
            year = year_elem.text if year_elem is not None else 'N/A'

            # ì´ˆë¡
            abstract_texts = []
            for abstract_elem in article_elem.findall('.//AbstractText'):
                if abstract_elem.text:
                    abstract_texts.append(abstract_elem.text)
            abstract = ' '.join(abstract_texts) if abstract_texts else 'No abstract available'

            # ë…¼ë¬¸ íƒ€ì…
            pub_type_elem = article_elem.find('.//PublicationType')
            study_type = pub_type_elem.text if pub_type_elem is not None else 'Unknown'

            return {
                'pmid': pmid,
                'title': title,
                'authors': authors,
                'journal': journal,
                'year': year,
                'abstract': abstract,
                'study_type': study_type,
                'url': f"https://pubmed.ncbi.nlm.nih.gov/{pmid}/"
            }

        except Exception as e:
            print(f"âœ— ë…¼ë¬¸ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
            return None

    def search_and_fetch(self, query: str, max_results: int = 12, strict: bool = False) -> List[Dict]:
        """ê²€ìƒ‰ê³¼ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°ë¥¼ í•œ ë²ˆì— ìˆ˜í–‰"""
        print(f"\nğŸ” '{query}' ê²€ìƒ‰ ì¤‘...")
        pmids = self.search(query, max_results, strict=strict)

        if not pmids:
            print("âœ— ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []

        print(f"\nğŸ“„ ë…¼ë¬¸ ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
        papers = self.fetch_details(pmids)

        print(f"\nâœ“ ì´ {len(papers)}ê°œ ë…¼ë¬¸ ìˆ˜ì§‘ ì™„ë£Œ\n")
        return papers
