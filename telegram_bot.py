"""
ë¸”ë¡œê·¸ ìë™ ìƒì„± í…”ë ˆê·¸ë¨ ë´‡

ì‹¤í–‰ ë°©ë²•:
    1. .env íŒŒì¼ì— TELEGRAM_BOT_TOKEN ì¶”ê°€
    2. python telegram_bot.py

ê¸°ëŠ¥:
    - í‚¤ì›Œë“œ ì…ë ¥ â†’ í† í”½ ë¶„ì„ â†’ ë‹¤ì¤‘ ì„ íƒ â†’ ë…¼ë¬¸ ê²€ìƒ‰/í™•ì¸ â†’ Hook ìŠ¤íƒ€ì¼ ì„ íƒ â†’ ë¸”ë¡œê·¸ ìƒì„±
"""

import os
import sys
import json
import asyncio
from datetime import datetime
from typing import Dict, List, Set

# í…”ë ˆê·¸ë¨ ë´‡ ë¼ì´ë¸ŒëŸ¬ë¦¬
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    CallbackQueryHandler,
    ConversationHandler,
    ContextTypes,
    filters,
)

# ê¸°ì¡´ ëª¨ë“ˆ ì„í¬íŠ¸
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from modules.smart_topic_extractor import SmartTopicExtractor
from modules.pubmed_search import PubMedSearcher
from modules.paper_analyzer import PaperAnalyzer
from modules.blog_generator import BlogGenerator
from modules.pmc_fulltext import PMCFullTextFetcher
from modules.llm_paper_analyzer import save_for_claude_analysis, create_batch_analysis_prompt
from modules.claude_paper_scorer import score_papers_with_claude
from modules.auto_blog_generator import generate_blog_auto, get_last_error_log
from config import Config

# ëŒ€í™” ìƒíƒœ ì •ì˜
(
    WAITING_KEYWORD,
    SELECTING_TOPICS,
    SEARCHING_PAPERS,
    SELECTING_HOOK_STYLE,
    CONFIRMING_DRAFT,
) = range(5)


class LoadingIndicator:
    """ë¡œë”© ì¤‘ ìƒíƒœë¥¼ ì£¼ê¸°ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self, bot, chat_id, base_message: str, interval: int = 10):
        self.bot = bot
        self.chat_id = chat_id
        self.base_message = base_message
        self.interval = interval
        self.message = None
        self.running = False
        self.task = None
        self.counter = 0
        self.dots = ["â³", "âŒ›"]

    async def start(self):
        """ë¡œë”© ì‹œì‘"""
        self.running = True
        self.counter = 0
        self.message = await self.bot.send_message(
            chat_id=self.chat_id,
            text=f"{self.dots[0]} {self.base_message}",
            parse_mode='Markdown'
        )
        self.task = asyncio.create_task(self._update_loop())

    async def _update_loop(self):
        """10ì´ˆë§ˆë‹¤ ë©”ì‹œì§€ ì—…ë°ì´íŠ¸"""
        while self.running:
            await asyncio.sleep(self.interval)
            if not self.running:
                break
            self.counter += 1
            elapsed = self.counter * self.interval
            dot = self.dots[self.counter % 2]
            try:
                await self.message.edit_text(
                    f"{dot} {self.base_message}\n\n"
                    f"â±ï¸ ì§„í–‰ ì¤‘... ({elapsed}ì´ˆ ê²½ê³¼)",
                    parse_mode='Markdown'
                )
            except:
                pass

    async def update(self, new_message: str):
        """ë©”ì‹œì§€ ì—…ë°ì´íŠ¸"""
        self.base_message = new_message
        if self.message:
            try:
                await self.message.edit_text(
                    f"â³ {new_message}",
                    parse_mode='Markdown'
                )
            except:
                pass

    async def stop(self, final_message: str = None):
        """ë¡œë”© ì¢…ë£Œ"""
        self.running = False
        if self.task:
            self.task.cancel()
            try:
                await self.task
            except asyncio.CancelledError:
                pass
        if final_message and self.message:
            try:
                await self.message.edit_text(final_message, parse_mode='Markdown')
            except:
                pass

    async def delete(self):
        """ë©”ì‹œì§€ ì‚­ì œ"""
        self.running = False
        if self.task:
            self.task.cancel()
        if self.message:
            try:
                await self.message.delete()
            except:
                pass

# Hook ìŠ¤íƒ€ì¼ ì •ì˜
HOOK_STYLES = {
    'stat_shock': {
        'name': 'ğŸ“Š ì¶©ê²© í†µê³„',
        'desc': '"í™˜ìì˜ 40%ëŠ” ì•½ì´ ë“£ì§€ ì•ŠìŠµë‹ˆë‹¤..."',
        'template': 'ì¶©ê²©ì ì¸ í†µê³„ë¡œ ì‹œì‘'
    },
    'counterintuitive': {
        'name': 'ğŸ”„ ë°˜ì§ê´€ ì§ˆë¬¸',
        'desc': '"ì»¤í”¼, ì •ë§ ëŠì–´ì•¼ í• ê¹Œìš”?"',
        'template': 'ìƒì‹ì„ ë’¤ì§‘ëŠ” ì§ˆë¬¸'
    },
    'reader_situation': {
        'name': 'ğŸ¯ ë…ì ê³µê°',
        'desc': '"ìë‹¤ê°€ ì†ì´ ì“°ë ¤ì„œ ê¹¼ìŠµë‹ˆë‹¤..."',
        'template': 'ë…ì ìƒí™© ë¬˜ì‚¬ (2ì¸ì¹­)'
    },
    'news_trend': {
        'name': 'ğŸ“° ë‰´ìŠ¤/íŠ¸ë Œë“œ',
        'desc': '"ìµœê·¼ ë°œí‘œëœ ì—°êµ¬ì— ë”°ë¥´ë©´..."',
        'template': 'ìµœì‹  ì—°êµ¬/ë‰´ìŠ¤ ì—°ê²°'
    },
    'conversation': {
        'name': 'ğŸ’¬ ëŒ€í™”ì²´',
        'desc': '"ê²€ìƒ‰í•´ë³´ë©´ ë‹¤ ë¹„ìŠ·í•œ ë§ë§Œ ë‚˜ì˜¤ì£ ?"',
        'template': 'ë…ìì™€ ëŒ€í™”í•˜ë“¯'
    },
    'case_study': {
        'name': 'ğŸ‘¤ ì‚¬ë¡€ ì†Œê°œ',
        'desc': '"35ì„¸ ì§ì¥ì¸ Aì”¨ëŠ”..."',
        'template': 'íƒ€ì¸ ì‚¬ë¡€ë¡œ ì‹œì‘'
    },
    'problem_direct': {
        'name': 'âš¡ ë¬¸ì œ ì§ê²©',
        'desc': '"ì•½ ë¨¹ì–´ë„ ì¬ë°œ. ì§„ì§œ ì›ì¸ì€..."',
        'template': 'PAS ê³µì‹ ì ìš©'
    },
    'curiosity': {
        'name': 'ğŸ”® í˜¸ê¸°ì‹¬ ìœ ë°œ',
        'desc': '"ê°€ì¥ ì¤‘ìš”í•œ ê±´ ì•½ë„ ì‹ë‹¨ë„ ì•„ë‹ˆì—ˆìŠµë‹ˆë‹¤..."',
        'template': 'ì˜¤í”ˆ ë£¨í”„ ê¸°ë²•'
    },
}


class BlogBotSession:
    """ì‚¬ìš©ìë³„ ì„¸ì…˜ ë°ì´í„° ê´€ë¦¬"""
    def __init__(self):
        self.keyword: str = ""
        self.keyword_en: str = ""
        self.topics: Dict[str, int] = {}  # í† í”½: ì–¸ê¸‰íšŸìˆ˜
        self.selected_topics: Set[str] = set()  # ì„ íƒëœ í† í”½ë“¤
        self.hook_style: str = ""
        self.papers: List[Dict] = []
        self.search_queries: List[str] = []  # ì‹¤ì œ ì‚¬ìš©ëœ PubMed ê²€ìƒ‰ ì¿¼ë¦¬
        self.draft: str = ""
        self.created_at: datetime = datetime.now()
        self.session_id: str = datetime.now().strftime('%Y%m%d_%H%M%S')

    def save_to_file(self, step: str = ""):
        """ì„¸ì…˜ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        import json
        save_dir = "session_data"
        os.makedirs(save_dir, exist_ok=True)

        filename = f"{save_dir}/{self.keyword}_{self.session_id}_{step}.json"
        data = {
            'keyword': self.keyword,
            'keyword_en': self.keyword_en,
            'topics': self.topics,
            'selected_topics': list(self.selected_topics),
            'hook_style': self.hook_style,
            'papers': self.papers,
            'search_queries': self.search_queries,
            'created_at': self.created_at.isoformat(),
            'step': step
        }
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"[ì„¸ì…˜ ì €ì¥] {filename}")

    @classmethod
    def load_from_file(cls, filepath: str) -> 'BlogBotSession':
        """íŒŒì¼ì—ì„œ ì„¸ì…˜ ë¶ˆëŸ¬ì˜¤ê¸°"""
        import json
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)

        session = cls()
        session.keyword = data.get('keyword', '')
        session.keyword_en = data.get('keyword_en', '')
        session.topics = data.get('topics', {})
        session.selected_topics = set(data.get('selected_topics', []))
        session.hook_style = data.get('hook_style', '')
        session.papers = data.get('papers', [])
        session.search_queries = data.get('search_queries', [])
        session.session_id = data.get('created_at', '')[:15].replace('-', '').replace('T', '_').replace(':', '')
        return session

    @staticmethod
    def list_saved_sessions() -> List[Dict]:
        """ì €ì¥ëœ ì„¸ì…˜ ëª©ë¡ ë°˜í™˜"""
        import glob
        save_dir = "session_data"
        if not os.path.exists(save_dir):
            return []

        # ê°€ì¥ ìµœê·¼ ë‹¨ê³„ì˜ íŒŒì¼ë§Œ (í‚¤ì›Œë“œ+ì„¸ì…˜IDë³„ë¡œ ê·¸ë£¹í•‘)
        files = glob.glob(f"{save_dir}/*.json")
        sessions = {}

        for f in files:
            try:
                import json
                with open(f, 'r', encoding='utf-8') as fp:
                    data = json.load(fp)
                key = f"{data.get('keyword')}_{data.get('created_at', '')[:10]}"
                step = data.get('step', '')

                # ë” ë†’ì€ ë‹¨ê³„ë§Œ ì €ì¥
                if key not in sessions or step > sessions[key].get('step', ''):
                    sessions[key] = {
                        'filepath': f,
                        'keyword': data.get('keyword'),
                        'step': step,
                        'papers_count': len(data.get('papers', [])),
                        'created_at': data.get('created_at', '')
                    }
            except:
                pass

        return sorted(sessions.values(), key=lambda x: x.get('created_at', ''), reverse=True)[:10]


# ì‚¬ìš©ìë³„ ì„¸ì…˜ ì €ì¥ì†Œ
user_sessions: Dict[int, BlogBotSession] = {}


def get_session(user_id: int) -> BlogBotSession:
    """ì‚¬ìš©ì ì„¸ì…˜ ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ìƒì„±)"""
    if user_id not in user_sessions:
        user_sessions[user_id] = BlogBotSession()
    return user_sessions[user_id]


async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """ë´‡ ì‹œì‘"""
    user_id = update.effective_user.id
    user_sessions[user_id] = BlogBotSession()  # ìƒˆ ì„¸ì…˜ ì‹œì‘

    await update.message.reply_text(
        "ğŸ‘‹ *ë¸”ë¡œê·¸ ìë™ ìƒì„± ë´‡*ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!\n\n"
        "ë¸”ë¡œê·¸ë¥¼ ì‘ì„±í•  *í‚¤ì›Œë“œ*ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\n"
        "ì˜ˆ: `ì—­ë¥˜ì„±ì‹ë„ì—¼`, `ë¹„íƒ€ë¯¼D ê²°í•`, `ê°„í—ì  ë‹¨ì‹`",
        parse_mode='Markdown'
    )
    return WAITING_KEYWORD


async def receive_keyword(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """í‚¤ì›Œë“œ ìˆ˜ì‹  ë° í† í”½ ë¶„ì„"""
    user_id = update.effective_user.id
    chat_id = update.effective_chat.id
    session = get_session(user_id)
    session.keyword = update.message.text.strip()

    # ë¡œë”© í‘œì‹œ ì‹œì‘
    loading = LoadingIndicator(
        context.bot,
        chat_id,
        f"*'{session.keyword}'* ë¶„ì„ ì¤‘...\nì¸ê¸° ë¸”ë¡œê·¸ ìˆ˜ì§‘ ë° Claude ë¶„ì„ ì§„í–‰"
    )
    await loading.start()

    try:
        # í† í”½ ì¶”ì¶œ (ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰)
        from concurrent.futures import ThreadPoolExecutor

        loop = asyncio.get_event_loop()
        extractor = SmartTopicExtractor()

        with ThreadPoolExecutor() as executor:
            result = await loop.run_in_executor(
                executor,
                extractor.extract_topics,
                session.keyword,
                15  # max_blogs
            )

        # ë¡œë”© ì¢…ë£Œ
        await loading.delete()

        session.keyword_en = result.get('main_keyword_en', session.keyword)

        # Claude ë¶„ì„ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
        by_category = result.get('by_category', {})
        trending = result.get('trending', [])

        # ì¹´í…Œê³ ë¦¬ ì •ì˜
        category_names = {
            'diet': 'ğŸ½ï¸ ìŒì‹/ì‹ì´',
            'treatment': 'ğŸ’Š ì¹˜ë£Œ/ì•½ë¬¼',
            'lifestyle': 'ğŸƒ ìƒí™œìŠµê´€',
            'symptom': 'ğŸ©º ì¦ìƒ',
            'general': 'ğŸ“Œ ê¸°íƒ€'
        }

        # ëª¨ë“  í† í”½ ìˆ˜ì§‘ (ì¹´í…Œê³ ë¦¬ë³„ + íŠ¸ë Œë”©)
        all_topics = {}  # {topic_name: category}

        # ì¹´í…Œê³ ë¦¬ë³„ í† í”½ ìˆ˜ì§‘
        for cat in category_names.keys():
            cat_topics = by_category.get(cat, [])
            for t in cat_topics:
                topic_name = t['topic']
                if topic_name not in all_topics:
                    all_topics[topic_name] = cat

        # íŠ¸ë Œë”© í† í”½ ì¶”ê°€
        for t in trending:
            topic_name = t['topic']
            if topic_name not in all_topics:
                all_topics[topic_name] = 'trending'

        # session.topicsì— ì €ì¥
        session.topics = all_topics

        # ì„¸ì…˜ ì €ì¥ (í‚¤ì›Œë“œ ë¶„ì„ ì™„ë£Œ)
        session.save_to_file("1_keyword_analyzed")

        # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„ ê²°ê³¼ ë©”ì‹œì§€ ìƒì„±
        analysis_msg = ""
        for cat, cat_name in category_names.items():
            cat_topics = by_category.get(cat, [])
            if cat_topics:
                topic_names = [t['topic'] for t in cat_topics]
                analysis_msg += f"{cat_name}: {', '.join(topic_names)}\n"

        # íŠ¸ë Œë”© í‚¤ì›Œë“œ ì¶”ê°€
        if trending:
            trending_names = [t['topic'] for t in trending]
            analysis_msg += f"ğŸ†• ì‹ ê·œë°œê²¬: {', '.join(trending_names)}\n"

        # í† í”½ ë²„íŠ¼ ìƒì„± (ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì •ë ¬, ëª¨ë“  í† í”½ í¬í•¨)
        keyboard = []
        cat_emoji_map = {'diet': 'ğŸ½ï¸', 'treatment': 'ğŸ’Š', 'lifestyle': 'ğŸƒ', 'symptom': 'ğŸ©º', 'general': 'ğŸ“Œ', 'trending': 'ğŸ†•'}

        for topic_name, cat in all_topics.items():
            cat_emoji = cat_emoji_map.get(cat, 'ğŸ“Œ')
            keyboard.append([
                InlineKeyboardButton(
                    f"â¬œ {cat_emoji} {topic_name}",
                    callback_data=f"topic:{topic_name[:30]}"
                )
            ])

        # ì™„ë£Œ/ì „ì²´ì„ íƒ/ê±´ë„ˆë›°ê¸° ë²„íŠ¼
        keyboard.append([
            InlineKeyboardButton("âœ… ì „ì²´ ì„ íƒ", callback_data="topic:SELECT_ALL"),
            InlineKeyboardButton("ğŸš€ ì„ íƒ ì™„ë£Œ", callback_data="topic:DONE"),
        ])
        keyboard.append([
            InlineKeyboardButton("â­ï¸ í† í”½ ì—†ì´ í‚¤ì›Œë“œë§Œ ê²€ìƒ‰", callback_data="topic:SKIP"),
        ])

        reply_markup = InlineKeyboardMarkup(keyboard)

        await context.bot.send_message(
            chat_id=chat_id,
            text=(
                f"ğŸ“Š *'{session.keyword}'* Claude ë¶„ì„ ì™„ë£Œ!\n\n"
                f"ğŸ“ ë¶„ì„ëœ ë¸”ë¡œê·¸: {result['blogs_analyzed']}ê°œ\n\n"
                f"*[ë¶„ì„ ê²°ê³¼]*\n{analysis_msg}\n"
                f"ğŸ‘‡ *ê¸€ì— í¬í•¨í•  í† í”½ì„ ì„ íƒí•˜ì„¸ìš”*"
            ),
            reply_markup=reply_markup,
            parse_mode='Markdown'
        )

        return SELECTING_TOPICS

    except Exception as e:
        # ë¡œë”© ì¢…ë£Œ
        await loading.delete()
        await context.bot.send_message(
            chat_id=chat_id,
            text=(
                f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\n"
                f"ì˜¤ë¥˜: {str(e)}\n\n"
                "/start ë¡œ ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”."
            )
        )
        return ConversationHandler.END


async def toggle_topic(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """í† í”½ ì„ íƒ/í•´ì œ í† ê¸€"""
    query = update.callback_query
    await query.answer()

    user_id = update.effective_user.id
    session = get_session(user_id)

    data = query.data.replace("topic:", "")

    if data == "DONE":
        # ì„ íƒ ì™„ë£Œ - ë‹¤ìŒ ë‹¨ê³„ë¡œ (ë…¼ë¬¸ ê²€ìƒ‰)
        return await search_papers_and_show(update, context)

    elif data == "SKIP":
        # í† í”½ ì„ íƒ ì—†ì´ ì§„í–‰ (í‚¤ì›Œë“œë§Œìœ¼ë¡œ ê²€ìƒ‰)
        session.selected_topics = set()
        return await search_papers_and_show(update, context)

    elif data == "SELECT_ALL":
        # ì „ì²´ ì„ íƒ (ëª¨ë“  í† í”½)
        session.selected_topics = set(session.topics.keys())

    else:
        # ê°œë³„ í† í”½ í† ê¸€
        if data in session.selected_topics:
            session.selected_topics.remove(data)
        else:
            session.selected_topics.add(data)

    # í‚¤ë³´ë“œ ì—…ë°ì´íŠ¸ (ëª¨ë“  í† í”½ í‘œì‹œ)
    keyboard = []
    cat_emoji_map = {'diet': 'ğŸ½ï¸', 'treatment': 'ğŸ’Š', 'lifestyle': 'ğŸƒ', 'symptom': 'ğŸ©º', 'general': 'ğŸ“Œ', 'trending': 'ğŸ†•'}

    for topic, category in session.topics.items():
        cat_emoji = cat_emoji_map.get(category, 'ğŸ“Œ')
        if topic in session.selected_topics:
            btn_text = f"âœ… {cat_emoji} {topic}"
        else:
            btn_text = f"â¬œ {cat_emoji} {topic}"
        keyboard.append([
            InlineKeyboardButton(btn_text, callback_data=f"topic:{topic[:30]}")
        ])

    keyboard.append([
        InlineKeyboardButton("âœ… ì „ì²´ ì„ íƒ", callback_data="topic:SELECT_ALL"),
        InlineKeyboardButton("ğŸš€ ì„ íƒ ì™„ë£Œ", callback_data="topic:DONE"),
    ])
    keyboard.append([
        InlineKeyboardButton("â­ï¸ í† í”½ ì—†ì´ í‚¤ì›Œë“œë§Œ ê²€ìƒ‰", callback_data="topic:SKIP"),
    ])

    reply_markup = InlineKeyboardMarkup(keyboard)

    selected_count = len(session.selected_topics)
    selected_list = ', '.join(list(session.selected_topics)[:5])
    if len(session.selected_topics) > 5:
        selected_list += f" ì™¸ {len(session.selected_topics) - 5}ê°œ"

    await query.edit_message_text(
        f"ğŸ“Š *'{session.keyword}'* Claude ë¶„ì„ ì™„ë£Œ!\n\n"
        f"âœ… *ì„ íƒëœ í† í”½: {selected_count}ê°œ*\n"
        f"{selected_list if selected_list else 'ì—†ìŒ'}\n\n"
        "ğŸ‘‡ í† í”½ì„ ì„ íƒí•˜ì„¸ìš”",
        reply_markup=reply_markup,
        parse_mode='Markdown'
    )

    return SELECTING_TOPICS


def escape_markdown(text: str) -> str:
    """Markdown íŠ¹ìˆ˜ë¬¸ì ì´ìŠ¤ì¼€ì´í”„"""
    special_chars = ['*', '_', '[', ']', '(', ')', '~', '`', '>', '#', '+', '-', '=', '|', '{', '}', '.', '!']
    for char in special_chars:
        text = text.replace(char, '\\' + char)
    return text


def extract_insight(paper: dict) -> str:
    """ë…¼ë¬¸ì—ì„œ ê²°ë¡  ì¶”ì¶œ í›„ í•œê¸€ ë²ˆì—­ (ì „ë¬¸ > ì´ˆë¡ ìˆœì„œë¡œ ì‹œë„)"""

    # 1ìˆœìœ„: PMC ì „ë¬¸ì˜ ê²°ë¡ 
    conclusion = paper.get("conclusion", "")
    # 2ìˆœìœ„: ì´ˆë¡
    abstract = paper.get("abstract", "")

    # ì‚¬ìš©í•  í…ìŠ¤íŠ¸ ê²°ì •
    if conclusion and len(conclusion) > 50:
        source_text = conclusion
        source_type = "ì „ë¬¸"
    elif abstract:
        source_text = abstract
        source_type = "ì´ˆë¡"
    else:
        return "ë‚´ìš© ì—†ìŒ"

    try:
        from deep_translator import GoogleTranslator

        # ë§ˆì§€ë§‰ 2-3ë¬¸ì¥ ì¶”ì¶œ (ê²°ë¡  ë¶€ë¶„)
        sentences = [s.strip() for s in source_text.replace('\n', ' ').split('. ') if s.strip()]

        if len(sentences) >= 3:
            insight_en = '. '.join(sentences[-3:])
        elif len(sentences) >= 2:
            insight_en = '. '.join(sentences[-2:])
        else:
            insight_en = sentences[-1] if sentences else source_text[:300]

        if not insight_en.endswith('.'):
            insight_en += '.'

        # ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸° (ë²ˆì—­ API ì œí•œ)
        if len(insight_en) > 1000:
            insight_en = insight_en[:1000]

        # í•œê¸€ë¡œ ë²ˆì—­
        translator = GoogleTranslator(source='en', target='ko')
        insight_kr = translator.translate(insight_en)

        # ì¶œì²˜ í‘œì‹œ
        if paper.get("has_fulltext"):
            prefix = "[ì „ë¬¸]"
        else:
            prefix = "[ì´ˆë¡]"

        return f"{prefix} {insight_kr}" if insight_kr else f"{prefix} {insight_en}"

    except Exception as e:
        sentences = [s.strip() for s in source_text.replace('\n', ' ').split('. ') if s.strip()]
        if len(sentences) >= 2:
            return "[ë²ˆì—­ì‹¤íŒ¨] " + '. '.join(sentences[-2:]) + '.'
        return "[ë²ˆì—­ì‹¤íŒ¨] " + (sentences[-1] + '.' if sentences else "ì¶”ì¶œ ì‹¤íŒ¨")


async def search_papers_and_show(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """ë…¼ë¬¸ ê²€ìƒ‰ í›„ ê²°ê³¼ í‘œì‹œ (Hook ìŠ¤íƒ€ì¼ ì„ íƒ ì „)"""
    query = update.callback_query
    user_id = update.effective_user.id
    chat_id = update.effective_chat.id
    session = get_session(user_id)

    selected_topics_str = ', '.join(list(session.selected_topics)[:5])
    if len(session.selected_topics) > 5:
        selected_topics_str += f" ì™¸ {len(session.selected_topics)-5}ê°œ"

    # ë¡œë”© í‘œì‹œ ì‹œì‘
    loading = LoadingIndicator(
        context.bot,
        chat_id,
        f"*ë…¼ë¬¸ ê²€ìƒ‰ ì¤‘...*\ní† í”½: {selected_topics_str}"
    )
    await loading.start()

    try:
        # PubMed ê²€ìƒ‰
        await loading.update("*PubMed ë…¼ë¬¸ ê²€ìƒ‰ ì¤‘...*")

        searcher = PubMedSearcher(
            email=Config.PUBMED_EMAIL,
            api_key=Config.PUBMED_API_KEY
        )

        all_papers = []
        search_queries_used = []  # ì‹¤ì œ ì‚¬ìš©ëœ ê²€ìƒ‰ ì¿¼ë¦¬ ê¸°ë¡

        if session.selected_topics:
            # í† í”½ì´ ì„ íƒëœ ê²½ìš°: í‚¤ì›Œë“œ + í† í”½ ì¡°í•© ê²€ìƒ‰
            for topic in list(session.selected_topics)[:5]:  # ìµœëŒ€ 5ê°œ í† í”½
                # í† í”½ì„ ì˜ì–´ë¡œ ë³€í™˜
                topic_en = SmartTopicExtractor.KR_TO_EN.get(topic, topic)

                # í† í”½ì´ í•œê¸€ì´ë©´ ë²ˆì—­ ì‹œë„
                if any('\uAC00' <= c <= '\uD7A3' for c in topic_en):  # í•œê¸€ í¬í•¨ ì²´í¬
                    try:
                        from deep_translator import GoogleTranslator
                        translator = GoogleTranslator(source='ko', target='en')
                        topic_en = translator.translate(topic)
                    except:
                        pass

                query_str = f"{session.keyword_en} AND {topic_en}"
                search_queries_used.append(query_str)
                print(f"[PubMed ê²€ìƒ‰] {query_str}")

                # í† í”½ë‹¹ 30í¸ì”© ê²€ìƒ‰
                papers = searcher.search_and_fetch(query_str, max_results=30)
                all_papers.extend(papers)
        else:
            # í† í”½ ì„ íƒ ì—†ì´ í‚¤ì›Œë“œë§Œìœ¼ë¡œ ê²€ìƒ‰
            query_str = session.keyword_en
            search_queries_used.append(query_str)
            print(f"[PubMed ê²€ìƒ‰] {query_str} (í‚¤ì›Œë“œë§Œ)")

            # í‚¤ì›Œë“œë§Œìœ¼ë¡œ 100í¸ ê²€ìƒ‰
            papers = searcher.search_and_fetch(query_str, max_results=100)
            all_papers.extend(papers)

        # ê²€ìƒ‰ ì¿¼ë¦¬ ì„¸ì…˜ì— ì €ì¥
        session.search_queries = search_queries_used

        # ì¤‘ë³µ ì œê±°
        seen_pmids = set()
        unique_papers = []
        for paper in all_papers:
            pmid = paper.get('pmid')
            if pmid and pmid not in seen_pmids:
                seen_pmids.add(pmid)
                unique_papers.append(paper)

        # ë…¼ë¬¸ì´ 5ê°œ ì´í•˜ë©´ í† í”½ ì œì™¸í•˜ê³  í‚¤ì›Œë“œë§Œìœ¼ë¡œ ì¬ê²€ìƒ‰
        if len(unique_papers) <= 5 and session.selected_topics:
            await loading.update(
                f"âš ï¸ *í† í”½ ì¡°í•© ê²°ê³¼ {len(unique_papers)}í¸ë¿*\ní‚¤ì›Œë“œë§Œìœ¼ë¡œ ì¬ê²€ìƒ‰ ì¤‘..."
            )

            # í‚¤ì›Œë“œë§Œìœ¼ë¡œ ì¬ê²€ìƒ‰
            query_str = session.keyword_en
            search_queries_used = [f"{query_str} (í‚¤ì›Œë“œë§Œ ì¬ê²€ìƒ‰)"]
            print(f"[PubMed ì¬ê²€ìƒ‰] {query_str} (í† í”½ ê²°ê³¼ ë¶€ì¡±ìœ¼ë¡œ í‚¤ì›Œë“œë§Œ)")

            all_papers = searcher.search_and_fetch(query_str, max_results=100)

            # ì¤‘ë³µ ì œê±°
            seen_pmids = set()
            unique_papers = []
            for paper in all_papers:
                pmid = paper.get('pmid')
                if pmid and pmid not in seen_pmids:
                    seen_pmids.add(pmid)
                    unique_papers.append(paper)

            session.search_queries = search_queries_used

        session.papers = unique_papers

        # PMCì—ì„œ ì „ë¬¸ ê°€ì ¸ì˜¤ê¸° (ìƒìœ„ 50í¸, ì´ 5ë¶„ ì œí•œ)
        import time
        PMC_MAX_PAPERS = 50  # ìƒìœ„ 50í¸ PMC ê²€ìƒ‰
        PMC_TIMEOUT_TOTAL = 300  # ì „ì²´ 5ë¶„ ì œí•œ

        papers_to_check = unique_papers[:PMC_MAX_PAPERS]
        await loading.update(f"*ë…¼ë¬¸ {len(unique_papers)}í¸ ìˆ˜ì§‘ ì™„ë£Œ!*\nPMC ì „ë¬¸ ê²€ìƒ‰ ì¤‘... (ìƒìœ„ {len(papers_to_check)}í¸)")

        pmc_fetcher = PMCFullTextFetcher(
            email=Config.PUBMED_EMAIL,
            api_key=Config.PUBMED_API_KEY
        )

        fulltext_count = 0
        pmc_start = time.time()

        for i, paper in enumerate(papers_to_check):
            # ì „ì²´ íƒ€ì„ì•„ì›ƒ ì²´í¬
            elapsed = int(time.time() - pmc_start)
            if elapsed > PMC_TIMEOUT_TOTAL:
                await loading.update(f"â±ï¸ PMC ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ ({elapsed}ì´ˆ)\nì „ë¬¸ {fulltext_count}í¸ í™•ë³´")
                break

            try:
                pmid = paper.get('pmid')
                if pmid:
                    fulltext_data = pmc_fetcher.get_paper_with_fulltext(pmid)
                    if fulltext_data:
                        paper["has_fulltext"] = True
                        paper["pmcid"] = fulltext_data.get("pmcid")
                        paper["conclusion"] = fulltext_data.get("conclusion", "")
                        paper["results"] = fulltext_data.get("results", "")
                        fulltext_count += 1
                    else:
                        paper["has_fulltext"] = False
            except Exception as e:
                paper["has_fulltext"] = False
                print(f"[PMC ì˜¤ë¥˜] PMID {paper.get('pmid')}: {e}")

            # 5ê°œë§ˆë‹¤ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
            if (i + 1) % 5 == 0:
                elapsed = int(time.time() - pmc_start)
                await loading.update(
                    f"*PMC ì „ë¬¸ ê²€ìƒ‰ ì¤‘...*\n({i+1}/{len(papers_to_check)}) ì „ë¬¸: {fulltext_count}í¸ ({elapsed}ì´ˆ)"
                )

        # ë‚˜ë¨¸ì§€ ë…¼ë¬¸ì€ ì „ë¬¸ ì—†ìŒìœ¼ë¡œ í‘œì‹œ
        for paper in unique_papers[PMC_MAX_PAPERS:]:
            paper["has_fulltext"] = False

        session.papers = unique_papers

        # Claude CLIë¡œ ê´€ë ¨ì„± ì ìˆ˜ í‰ê°€ (íƒ€ì„ì•„ì›ƒ ì ìš©)
        await loading.update("*Claudeê°€ ê´€ë ¨ì„± ì ìˆ˜ í‰ê°€ ì¤‘...*\n75ì  ì´ìƒë§Œ ì±„íƒë©ë‹ˆë‹¤ (ìµœëŒ€ 3ë¶„)")

        try:
            import concurrent.futures
            claude_start = time.time()
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(
                    score_papers_with_claude,
                    unique_papers,
                    session.keyword,
                    session.keyword_en,
                    list(session.selected_topics)
                )
                try:
                    accepted_papers, rejected_papers = future.result(timeout=180)  # 3ë¶„ íƒ€ì„ì•„ì›ƒ
                except concurrent.futures.TimeoutError:
                    await loading.update("âš ï¸ Claude ì ìˆ˜ í‰ê°€ íƒ€ì„ì•„ì›ƒ - ì „ì²´ ë…¼ë¬¸ ì‚¬ìš©")
                    accepted_papers = unique_papers
                    rejected_papers = []

            claude_elapsed = int(time.time() - claude_start)
            print(f"[Claude ì ìˆ˜í‰ê°€] {claude_elapsed}ì´ˆ, ì±„íƒ: {len(accepted_papers)}í¸")

        except Exception as e:
            print(f"[Claude ì ìˆ˜í‰ê°€ ì˜¤ë¥˜] {e}")
            await loading.update(f"âš ï¸ Claude ì ìˆ˜ í‰ê°€ ì‹¤íŒ¨: {str(e)[:100]}")
            accepted_papers = unique_papers
            rejected_papers = []

        session.papers = accepted_papers if accepted_papers else unique_papers  # ì±„íƒëœ ë…¼ë¬¸ë§Œ ì €ì¥

        # ì „ë¬¸ í†µê³„ ê³„ì‚°
        fulltext_papers = [p for p in session.papers if p.get('has_fulltext')]

        # ê²€ìƒ‰ ì¿¼ë¦¬ í‘œì‹œ (ìµœëŒ€ 3ê°œ)
        queries_display = "\n".join([f"  â€¢ {q}" for q in session.search_queries[:3]])
        if len(session.search_queries) > 3:
            queries_display += f"\n  ...ì™¸ {len(session.search_queries)-3}ê°œ"

        # ì„¸ì…˜ ì €ì¥ (ë…¼ë¬¸ ê²€ìƒ‰ ì™„ë£Œ)
        session.save_to_file("2_papers_searched")

        # ë¡œë”© ì¢…ë£Œ
        await loading.delete()

        # ì²« ë²ˆì§¸ ë©”ì‹œì§€: ìš”ì•½ ì •ë³´
        header_msg = (
            f"ğŸ“š *ë…¼ë¬¸ ê²€ìƒ‰ ì™„ë£Œ!*\n\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"ğŸ“Œ í‚¤ì›Œë“œ: {session.keyword} ({session.keyword_en})\n"
            f"ğŸ·ï¸ ì„ íƒ í† í”½: {', '.join(list(session.selected_topics))}\n"
            f"ğŸ“„ ìˆ˜ì§‘ ë…¼ë¬¸: {len(unique_papers)}í¸\n"
            f"âœ… *ì±„íƒ ë…¼ë¬¸: {len(accepted_papers)}í¸* (75ì  ì´ìƒ)\n"
            f"âŒ ë¯¸ì±„íƒ: {len(rejected_papers)}í¸\n"
            f"ğŸ“— ì „ë¬¸ í™•ë³´: {len(fulltext_papers)}í¸\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
            f"ğŸ” *ì‹¤ì œ ê²€ìƒ‰ ì¿¼ë¦¬:*\n{queries_display}\n\n"
            f"ğŸ“— = ì „ë¬¸ | ğŸ“„ = ì´ˆë¡ | ğŸ¯ = ê´€ë ¨ì„± ì ìˆ˜\n\n"
            f"ğŸ“‘ *ì±„íƒëœ ë…¼ë¬¸ ëª©ë¡:*\n"
        )

        await context.bot.send_message(chat_id=chat_id, text=header_msg, parse_mode='Markdown')

        # ì§„í–‰ ìƒí™© ë©”ì‹œì§€
        progress_msg = await context.bot.send_message(
            chat_id=chat_id,
            text=f"ğŸ“– ë…¼ë¬¸ ë¶„ì„ ì¤‘... (0/{len(unique_papers)})"
        )

        paper_messages = []
        current_msg = ""

        for i, paper in enumerate(unique_papers, 1):
            # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ (10ê°œë§ˆë‹¤)
            if i % 10 == 0:
                try:
                    await progress_msg.edit_text(f"ğŸ“– ë…¼ë¬¸ ë¶„ì„ ì¤‘... ({i}/{len(unique_papers)})")
                except:
                    pass

            title = paper.get('title', 'ì œëª© ì—†ìŒ')
            journal = paper.get('journal', 'ì €ë„ ë¯¸ìƒ')
            year = paper.get('year', 'ì—°ë„ ë¯¸ìƒ')
            has_fulltext = paper.get('has_fulltext', False)
            relevance_score = paper.get('ê´€ë ¨ì„±ì ìˆ˜')
            score_reason = paper.get('ì ìˆ˜ê·¼ê±°', '')

            try:
                insight = extract_insight(paper)
            except Exception as e:
                insight = "ë²ˆì—­ ì‹¤íŒ¨"

            # ì „ë¬¸ ì—¬ë¶€ í‘œì‹œ
            fulltext_marker = "ğŸ“—" if has_fulltext else "ğŸ“„"

            # ê´€ë ¨ì„± ì ìˆ˜ í‘œì‹œ (0ì ë„ í‘œì‹œ)
            score_display = f"ğŸ¯{relevance_score}ì " if relevance_score is not None else ""

            # ì „ë¬¸ ì—¬ë¶€ì— ë”°ë¼ ë‹¤ë¥¸ ì•„ì´ì½˜ í‘œì‹œ
            paper_text = (
                f"{fulltext_marker} {i}. [{score_display}] {title}\n"
                f"   ğŸ“° {journal}, {year}\n"
                f"   ğŸ’¡ {insight}\n\n"
            )

            # ë©”ì‹œì§€ ê¸¸ì´ ì²´í¬ (3500ì ë„˜ìœ¼ë©´ ë¶„ë¦¬)
            if len(current_msg) + len(paper_text) > 3500:
                paper_messages.append(current_msg)
                current_msg = paper_text
            else:
                current_msg += paper_text

        if current_msg:
            paper_messages.append(current_msg)

        # ì§„í–‰ ë©”ì‹œì§€ ì‚­ì œ
        try:
            await progress_msg.delete()
        except:
            pass

        # ë…¼ë¬¸ ëª©ë¡ ë©”ì‹œì§€ë“¤ ì „ì†¡ (Markdown ì—†ì´ ì¼ë°˜ í…ìŠ¤íŠ¸)
        for msg in paper_messages:
            try:
                await context.bot.send_message(
                    chat_id=chat_id,
                    text=msg
                )
            except Exception as e:
                # ì‹¤íŒ¨ì‹œ ì§§ê²Œ ì˜ë¼ì„œ ì¬ì‹œë„
                await context.bot.send_message(
                    chat_id=chat_id,
                    text=msg[:4000] + "..."
                )

        # ë§ˆì§€ë§‰: í™•ì¸ ë²„íŠ¼
        keyboard = [
            [InlineKeyboardButton("âœ… ë…¼ë¬¸ í™•ì¸ ì™„ë£Œ, ë„ì…ë¶€ ìŠ¤íƒ€ì¼ ì„ íƒ", callback_data="papers:CONFIRM")]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)

        await context.bot.send_message(
            chat_id=chat_id,
            text=(
                f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                f"ì´ *{len(session.papers)}í¸*ì˜ ë…¼ë¬¸ì„ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.\n\n"
                f"ìœ„ ë…¼ë¬¸ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ë¸”ë¡œê·¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.\n"
                f"í™•ì¸ í›„ ë„ì…ë¶€ ìŠ¤íƒ€ì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”."
            ),
            reply_markup=reply_markup,
            parse_mode='Markdown'
        )

        return SEARCHING_PAPERS

    except Exception as e:
        # ë¡œë”© ì¢…ë£Œ
        await loading.delete()
        await context.bot.send_message(
            chat_id=chat_id,
            text=(
                f"âŒ ë…¼ë¬¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\n"
                f"ì˜¤ë¥˜: {str(e)}\n\n"
                "/start ë¡œ ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”."
            )
        )
        return ConversationHandler.END


async def handle_paper_result(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """ë…¼ë¬¸ ê²°ê³¼ í™•ì¸ í›„ Hook ìŠ¤íƒ€ì¼ ì„ íƒìœ¼ë¡œ ì´ë™"""
    query = update.callback_query
    await query.answer()

    action = query.data.replace("papers:", "")

    if action == "CONFIRM":
        return await show_hook_styles(update, context)

    return SEARCHING_PAPERS


async def show_hook_styles(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """Hook ìŠ¤íƒ€ì¼ ì„ íƒ í™”ë©´"""
    query = update.callback_query
    user_id = update.effective_user.id
    session = get_session(user_id)

    # Hook ìŠ¤íƒ€ì¼ í‚¤ë³´ë“œ
    keyboard = []
    for style_id, style_info in HOOK_STYLES.items():
        keyboard.append([
            InlineKeyboardButton(
                f"{style_info['name']}",
                callback_data=f"hook:{style_id}"
            )
        ])

    keyboard.append([
        InlineKeyboardButton("ğŸ² ëœë¤ ì„ íƒ", callback_data="hook:RANDOM")
    ])

    reply_markup = InlineKeyboardMarkup(keyboard)

    selected_topics_str = ', '.join(list(session.selected_topics)[:5])
    if len(session.selected_topics) > 5:
        selected_topics_str += f" ì™¸ {len(session.selected_topics)-5}ê°œ"

    await query.edit_message_text(
        f"âœ… *í† í”½ ì„ íƒ ì™„ë£Œ!*\n\n"
        f"ğŸ“Œ ì„ íƒëœ í† í”½: {selected_topics_str}\n\n"
        "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
        "âœï¸ *ë„ì…ë¶€ ìŠ¤íƒ€ì¼ì„ ì„ íƒí•˜ì„¸ìš”:*\n\n"
        "ğŸ“Š *ì¶©ê²© í†µê³„* - ìˆ«ìë¡œ ì„íŒ©íŠ¸\n"
        "ğŸ”„ *ë°˜ì§ê´€ ì§ˆë¬¸* - ìƒì‹ ë’¤ì§‘ê¸°\n"
        "ğŸ¯ *ë…ì ê³µê°* - ìƒí™© ë¬˜ì‚¬\n"
        "ğŸ“° *ë‰´ìŠ¤/íŠ¸ë Œë“œ* - ìµœì‹  ì—°êµ¬\n"
        "ğŸ’¬ *ëŒ€í™”ì²´* - ì¹œê·¼í•œ í†¤\n"
        "ğŸ‘¤ *ì‚¬ë¡€ ì†Œê°œ* - ìŠ¤í† ë¦¬í…”ë§\n"
        "âš¡ *ë¬¸ì œ ì§ê²©* - PAS ê³µì‹\n"
        "ğŸ”® *í˜¸ê¸°ì‹¬ ìœ ë°œ* - ì˜¤í”ˆ ë£¨í”„",
        reply_markup=reply_markup,
        parse_mode='Markdown'
    )

    return SELECTING_HOOK_STYLE


async def select_hook_style(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """Hook ìŠ¤íƒ€ì¼ ì„ íƒ (ë…¼ë¬¸ì€ ì´ë¯¸ ê²€ìƒ‰ë¨)"""
    query = update.callback_query
    await query.answer()

    user_id = update.effective_user.id
    session = get_session(user_id)

    style_id = query.data.replace("hook:", "")

    if style_id == "RANDOM":
        import random
        style_id = random.choice(list(HOOK_STYLES.keys()))

    session.hook_style = style_id
    style_info = HOOK_STYLES[style_id]

    # ì„¸ì…˜ ì €ì¥ (ìŠ¤íƒ€ì¼ ì„ íƒ ì™„ë£Œ)
    session.save_to_file("3_style_selected")

    # ì´ˆì•ˆ ìƒì„± í™•ì¸ (ë…¼ë¬¸ì€ ì´ë¯¸ ê²€ìƒ‰ë˜ì–´ ìˆìŒ)
    keyboard = [
        [
            InlineKeyboardButton("âœ… ë¸”ë¡œê·¸ ìƒì„±", callback_data="confirm:YES"),
            InlineKeyboardButton("ğŸ”„ ìŠ¤íƒ€ì¼ ë³€ê²½", callback_data="confirm:CHANGE_STYLE"),
        ],
        [
            InlineKeyboardButton("âŒ ì·¨ì†Œ", callback_data="confirm:CANCEL"),
        ]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)

    await query.edit_message_text(
        f"âœ… *ëª¨ë“  ì„¤ì • ì™„ë£Œ!*\n\n"
        f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        f"ğŸ“Œ í‚¤ì›Œë“œ: {session.keyword}\n"
        f"ğŸ·ï¸ ì„ íƒ í† í”½: {len(session.selected_topics)}ê°œ\n"
        f"ğŸ“„ ìˆ˜ì§‘ ë…¼ë¬¸: {len(session.papers)}í¸\n"
        f"âœï¸ ë„ì… ìŠ¤íƒ€ì¼: {style_info['name']}\n"
        f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
        f"ì´ëŒ€ë¡œ ë¸”ë¡œê·¸ë¥¼ ìƒì„±í• ê¹Œìš”?",
        reply_markup=reply_markup,
        parse_mode='Markdown'
    )

    return CONFIRMING_DRAFT


async def confirm_generation(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """ë¸”ë¡œê·¸ ìƒì„± í™•ì¸"""
    query = update.callback_query
    await query.answer()

    user_id = update.effective_user.id
    session = get_session(user_id)

    action = query.data.replace("confirm:", "")

    if action == "CANCEL":
        await query.edit_message_text(
            "âŒ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.\n\n"
            "/start ë¡œ ë‹¤ì‹œ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
        return ConversationHandler.END

    elif action == "CHANGE_STYLE":
        return await show_hook_styles(update, context)

    elif action == "YES":
        chat_id = update.effective_chat.id

        # Hook ìŠ¤íƒ€ì¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        style_info = HOOK_STYLES[session.hook_style]
        fulltext_count = sum(1 for p in session.papers if p.get('has_fulltext'))

        await query.edit_message_text(
            f"ğŸ¤– *ë¸”ë¡œê·¸ ìë™ ìƒì„± ì‹œì‘!*\n\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"ğŸ“Œ í‚¤ì›Œë“œ: {session.keyword}\n"
            f"ğŸ·ï¸ í† í”½: {', '.join(list(session.selected_topics)[:3])}\n"
            f"ğŸ“„ ë…¼ë¬¸: {len(session.papers)}í¸\n"
            f"âœï¸ ìŠ¤íƒ€ì¼: {style_info['name']}\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
            parse_mode='Markdown'
        )

        # ì„¸ì…˜ ì €ì¥ (ë¸”ë¡œê·¸ ìƒì„± ì‹œì‘ ì „)
        session.save_to_file("4_generation_started")

        # ë¡œë”© í‘œì‹œ ì‹œì‘
        loading = LoadingIndicator(
            context.bot,
            chat_id,
            "*ë…¼ë¬¸ ë¶„ì„ ë° ë¸”ë¡œê·¸ ìƒì„± ì¤‘...*\nClaudeê°€ ë…¼ë¬¸ì„ ë¶„ì„í•˜ê³  HTMLì„ ìƒì„±í•©ë‹ˆë‹¤."
        )
        await loading.start()

        try:
            # ì„¸ì…˜ ë°ì´í„° êµ¬ì„±
            session_data = {
                'keyword': session.keyword,
                'keyword_en': session.keyword_en,
                'topics': list(session.selected_topics),
                'hook_style': session.hook_style,
                'hook_style_name': style_info['name'],
                'hook_style_desc': style_info['desc'],
                'hook_style_template': style_info['template'],
                'papers': session.papers,
            }

            # ë””ë²„ê·¸ ë¡œê¹…
            print(f"[TG DEBUG] keyword={session.keyword}")
            print(f"[TG DEBUG] topics={list(session.selected_topics)}")
            print(f"[TG DEBUG] papers={len(session.papers)}í¸")
            print(f"[TG DEBUG] hook_style={session.hook_style}")
            if session.papers:
                print(f"[TG DEBUG] ì²« ë…¼ë¬¸: {session.papers[0].get('title', 'N/A')[:50]}")

            # ìë™ ë¸”ë¡œê·¸ ìƒì„± (ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰)
            import asyncio
            from concurrent.futures import ThreadPoolExecutor

            # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ í•¨ìˆ˜
            async def update_progress(step: int, message: str):
                try:
                    await context.bot.send_message(
                        chat_id=chat_id,
                        text=f"â³ *{step}ë‹¨ê³„:* {message}",
                        parse_mode='Markdown'
                    )
                except:
                    pass

            # ë¸”ë¡œê·¸ ìƒì„± ì‹¤í–‰
            loop = asyncio.get_event_loop()
            with ThreadPoolExecutor() as executor:
                html_path = await loop.run_in_executor(
                    executor,
                    generate_blog_auto,
                    session_data,
                    "output"
                )

            # ë¡œë”© ì¢…ë£Œ
            await loading.delete()

            if html_path and os.path.exists(html_path):
                # ì„±ê³µ - HTML íŒŒì¼ ì „ì†¡
                await context.bot.send_message(
                    chat_id=chat_id,
                    text=(
                        f"âœ… *ë¸”ë¡œê·¸ ìƒì„± ì™„ë£Œ!*\n\n"
                        f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                        f"ğŸ“Œ í‚¤ì›Œë“œ: {session.keyword}\n"
                        f"ğŸ·ï¸ í† í”½: {', '.join(list(session.selected_topics)[:3])}\n"
                        f"ğŸ“„ ì°¸ê³  ë…¼ë¬¸: {len(session.papers)}í¸\n"
                        f"âœï¸ ìŠ¤íƒ€ì¼: {style_info['name']}\n"
                        f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
                        f"ğŸ“ HTML íŒŒì¼ì„ ì „ì†¡í•©ë‹ˆë‹¤..."
                    ),
                    parse_mode='Markdown'
                )

                # HTML íŒŒì¼ ì „ì†¡
                with open(html_path, 'rb') as f:
                    await context.bot.send_document(
                        chat_id=chat_id,
                        document=f,
                        filename=os.path.basename(html_path),
                        caption=f"ğŸ“ {session.keyword} ë¸”ë¡œê·¸ HTML\në„¤ì´ë²„ ë¸”ë¡œê·¸ì— HTML ëª¨ë“œë¡œ ë¶™ì—¬ë„£ê¸° í•˜ì„¸ìš”!"
                    )

                # HTML ë¯¸ë¦¬ë³´ê¸° (ì¼ë¶€)
                with open(html_path, 'r', encoding='utf-8') as f:
                    html_preview = f.read()[:500] + "..."

                await context.bot.send_message(
                    chat_id=chat_id,
                    text=f"ğŸ“„ *HTML ë¯¸ë¦¬ë³´ê¸°:*\n```html\n{html_preview}\n```\n\n/start ë¡œ ìƒˆ ë¸”ë¡œê·¸ ì‘ì„±",
                    parse_mode='Markdown'
                )

            else:
                # ì‹¤íŒ¨ - ì—ëŸ¬ ë¡œê·¸ í‘œì‹œ
                error_logs = get_last_error_log()
                error_text = "\n".join(error_logs[-10:]) if error_logs else "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"

                await context.bot.send_message(
                    chat_id=chat_id,
                    text=(
                        f"âŒ *ë¸”ë¡œê·¸ ìƒì„± ì‹¤íŒ¨*\n\n"
                        f"ë…¼ë¬¸: {len(session.papers)}í¸\n"
                        f"í† í”½: {', '.join(list(session.selected_topics)[:3]) if session.selected_topics else 'ì—†ìŒ'}\n\n"
                        f"ğŸ“‹ *ì—ëŸ¬ ë¡œê·¸:*\n```\n{error_text[:1500]}\n```\n\n"
                        f"/start ë¡œ ìƒˆ ë¸”ë¡œê·¸ ì‘ì„±"
                    ),
                    parse_mode='Markdown'
                )

            return ConversationHandler.END

        except Exception as e:
            # ë¡œë”© ì¢…ë£Œ
            await loading.delete()

            # ì—ëŸ¬ ë¡œê·¸ í¬í•¨
            error_logs = get_last_error_log()
            error_text = "\n".join(error_logs[-5:]) if error_logs else ""

            await context.bot.send_message(
                chat_id=chat_id,
                text=(
                    f"âŒ ë¸”ë¡œê·¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\n"
                    f"ì˜¤ë¥˜: {str(e)}\n\n"
                    f"ğŸ“‹ ë¡œê·¸:\n```\n{error_text[:1000]}\n```\n\n"
                    "/start ë¡œ ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”."
                ),
                parse_mode='Markdown'
            )
            return ConversationHandler.END


def generate_blog_html(session: BlogBotSession) -> str:
    """ì„¸ì…˜ ë°ì´í„°ë¡œ ë¸”ë¡œê·¸ HTML ìƒì„± (AI ê¸°ë°˜)"""
    style_info = HOOK_STYLES[session.hook_style]

    # API í‚¤ í™•ì¸
    api_key = Config.ANTHROPIC_API_KEY
    if not api_key or api_key == "your_api_key_here":
        # API í‚¤ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©
        return generate_blog_html_fallback(session)

    try:
        # 1. ë…¼ë¬¸ ë¶„ì„ (Claude AI)
        analyzer = PaperAnalyzer(api_key=api_key)
        analysis = analyzer.analyze_papers(session.papers, session.keyword)

        # 2. Hook ìŠ¤íƒ€ì¼ ì •ë³´ë¥¼ ë¶„ì„ì— ì¶”ê°€
        analysis['hook_style'] = session.hook_style
        analysis['hook_info'] = style_info
        analysis['selected_topics'] = list(session.selected_topics)

        # 3. ë¸”ë¡œê·¸ ìƒì„± (Claude AI)
        generator = BlogGenerator(api_key=api_key)

        # ìŠ¤íƒ€ì¼ ë§¤í•‘: hook_styleì„ blog_styleë¡œ ë³€í™˜
        style_map = {
            'stat_shock': 'hybrid',       # í†µê³„ ê°•ì¡°
            'counterintuitive': 'casual', # ì§ˆë¬¸í˜•
            'reader_situation': 'casual', # ê³µê°í˜•
            'news_trend': 'hybrid',       # ë‰´ìŠ¤í˜•
            'conversation': 'casual',     # ëŒ€í™”ì²´
            'case_study': 'casual',       # ì‚¬ë¡€í˜•
            'problem_direct': 'hybrid',   # ë¬¸ì œ ì§ê²©
            'curiosity': 'casual',        # í˜¸ê¸°ì‹¬í˜•
        }
        blog_style = style_map.get(session.hook_style, 'hybrid')

        # Hook ìŠ¤íƒ€ì¼ë³„ ì¶”ê°€ ì§€ì¹¨ì„ ë¶„ì„ì— í¬í•¨
        hook_instructions = get_hook_instructions(session.hook_style, session.keyword)
        if 'raw_analysis' in analysis:
            analysis['raw_analysis'] = hook_instructions + "\n\n" + analysis['raw_analysis']
        else:
            analysis['hook_instructions'] = hook_instructions

        html_content = generator.generate_blog_post(
            topic=session.keyword,
            analysis=analysis,
            style=blog_style
        )

        return html_content

    except Exception as e:
        print(f"AI ìƒì„± ì‹¤íŒ¨, ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©: {e}")
        return generate_blog_html_fallback(session)


def get_hook_instructions(hook_style: str, keyword: str) -> str:
    """Hook ìŠ¤íƒ€ì¼ë³„ ê¸€ì“°ê¸° ì§€ì¹¨"""
    instructions = {
        'stat_shock': f"""
## ë„ì…ë¶€ ìŠ¤íƒ€ì¼: ì¶©ê²© í†µê³„
- ê°€ì¥ ë†€ë¼ìš´ í†µê³„ ìˆ˜ì¹˜ë¡œ ì‹œì‘í•˜ì„¸ìš”
- "XX% ì˜ ì‚¬ëŒë“¤ì´...", "10ëª… ì¤‘ Xëª…ì€..." í˜•ì‹ ì‚¬ìš©
- ë…ìê°€ "ì •ë§?" í•˜ê³  ë†€ë„ ë§Œí•œ ìˆ«ì ì„ íƒ
- ì˜ˆ: "{keyword} í™˜ìì˜ 40%ëŠ” ì•½ì´ ë“£ì§€ ì•ŠìŠµë‹ˆë‹¤..."
""",
        'counterintuitive': f"""
## ë„ì…ë¶€ ìŠ¤íƒ€ì¼: ë°˜ì§ê´€ ì§ˆë¬¸
- ìƒì‹ì„ ë’¤ì§‘ëŠ” ì§ˆë¬¸ìœ¼ë¡œ ì‹œì‘í•˜ì„¸ìš”
- ë…ìê°€ "ë‹¹ì—°íˆ ê·¸ë ‡ì§€ ì•Šë‚˜?"ë¼ê³  ìƒê°í•˜ëŠ” ê²ƒì— ë„ì „
- ì˜ˆ: "ì»¤í”¼, ì •ë§ ëŠì–´ì•¼ í• ê¹Œìš”?", "{keyword}ì— ëŒ€í•œ ì´ ìƒì‹, í‹€ë ¸ìŠµë‹ˆë‹¤"
""",
        'reader_situation': f"""
## ë„ì…ë¶€ ìŠ¤íƒ€ì¼: ë…ì ê³µê°
- 2ì¸ì¹­ìœ¼ë¡œ ë…ìì˜ ìƒí™©ì„ ë¬˜ì‚¬í•˜ì„¸ìš”
- "í˜¹ì‹œ ~í•˜ì‹  ì  ìˆìœ¼ì‹ ê°€ìš”?", "~ë•Œë¬¸ì— ê³ ë¯¼ì´ì‹œì£ ?"
- ë…ìê°€ "ì–´, ì´ê±° ë‚´ ì–˜ê¸°ë‹¤!" ëŠë¼ê²Œ
- ì˜ˆ: "ìë‹¤ê°€ ì†ì´ ì“°ë ¤ì„œ ê¹¬ ì  ìˆìœ¼ì‹œì£ ?", "{keyword} ë•Œë¬¸ì— ë°¤ì  ì„¤ì¹˜ì‹  ë¶„ë“¤..."
""",
        'news_trend': f"""
## ë„ì…ë¶€ ìŠ¤íƒ€ì¼: ë‰´ìŠ¤/íŠ¸ë Œë“œ
- ìµœì‹  ì—°êµ¬ ë°œí‘œ ì†Œì‹ìœ¼ë¡œ ì‹œì‘í•˜ì„¸ìš”
- "ìµœê·¼ ì—°êµ¬ì—ì„œ ë°í˜€ì§„...", "2024ë…„ ë°œí‘œëœ ë…¼ë¬¸ì— ë”°ë¥´ë©´..."
- ê¶Œìœ„ ìˆëŠ” ì €ë„ ì´ë¦„ ì–¸ê¸‰
- ì˜ˆ: "ìµœê·¼ JAMAì— ë°œí‘œëœ ì—°êµ¬ê°€ {keyword}ì— ëŒ€í•œ ìƒˆë¡œìš´ ì‚¬ì‹¤ì„ ë°í˜”ìŠµë‹ˆë‹¤"
""",
        'conversation': f"""
## ë„ì…ë¶€ ìŠ¤íƒ€ì¼: ëŒ€í™”ì²´
- ì¹œêµ¬ì—ê²Œ ë§í•˜ë“¯ í¸í•˜ê²Œ ì‹œì‘í•˜ì„¸ìš”
- "~í•˜ì£ ?", "~ì–ì•„ìš”" ì–´ë¯¸ ì‚¬ìš©
- ë…ìì™€ ìˆ˜ë‹¤ ë– ëŠ” ëŠë‚Œ
- ì˜ˆ: "{keyword} ê²€ìƒ‰í•˜ë©´ ë‹¤ ë¹„ìŠ·í•œ ë§ë§Œ ë‚˜ì˜¤ì–ì•„ìš”?"
""",
        'case_study': f"""
## ë„ì…ë¶€ ìŠ¤íƒ€ì¼: ì‚¬ë¡€ ì†Œê°œ
- ê°€ìƒì˜ í™˜ì/ì‚¬ë¡€ë¡œ ì‹œì‘í•˜ì„¸ìš”
- "30ëŒ€ ì§ì¥ì¸ Aì”¨ëŠ”...", "ì£¼ë¶€ Bì”¨ì˜ ê²½í—˜ë‹´"
- ìŠ¤í† ë¦¬í…”ë§ìœ¼ë¡œ ëª°ì…ê° ì œê³µ
- ì˜ˆ: "35ì„¸ ì§ì¥ì¸ Aì”¨ëŠ” 1ë…„ ë„˜ê²Œ {keyword}ìœ¼ë¡œ ê³ ìƒí•˜ê³  ìˆì—ˆìŠµë‹ˆë‹¤..."
""",
        'problem_direct': f"""
## ë„ì…ë¶€ ìŠ¤íƒ€ì¼: ë¬¸ì œ ì§ê²©
- ë¬¸ì œì ì„ ë°”ë¡œ ì§€ì í•˜ë©° ì‹œì‘í•˜ì„¸ìš”
- PAS ê³µì‹: Problem(ë¬¸ì œ) â†’ Agitate(ìê·¹) â†’ Solution(í•´ê²°ì±…)
- ê¸°ì¡´ ë°©ë²•ì˜ í•œê³„ ì–¸ê¸‰
- ì˜ˆ: "ì•½ ë¨¹ì–´ë„ ì¬ë°œ. {keyword}ì˜ ì§„ì§œ ì›ì¸ì€ ë”°ë¡œ ìˆìŠµë‹ˆë‹¤"
""",
        'curiosity': f"""
## ë„ì…ë¶€ ìŠ¤íƒ€ì¼: í˜¸ê¸°ì‹¬ ìœ ë°œ
- ê²°ë¡ ì„ ì‚´ì§ ì•”ì‹œë§Œ í•˜ê³  ì‹œì‘í•˜ì„¸ìš”
- ì˜¤í”ˆ ë£¨í”„: ì •ë³´ì˜ ê³µë°±ì„ ë§Œë“¤ì–´ ê¶ê¸ˆì¦ ìœ ë°œ
- "ê°€ì¥ ì¤‘ìš”í•œ ê±´... ë‚˜ì¤‘ì— ì•Œë ¤ë“œë¦´ê²Œìš”" ëŠë‚Œ
- ì˜ˆ: "{keyword}ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ê±´ ì•½ë„ ì‹ë‹¨ë„ ì•„ë‹ˆì—ˆìŠµë‹ˆë‹¤. ê·¸ê²Œ ë­˜ê¹Œìš”?"
""",
    }

    return instructions.get(hook_style, "")


def generate_blog_html_fallback(session: BlogBotSession) -> str:
    """API í‚¤ ì—†ì„ ë•Œ ì‚¬ìš©í•˜ëŠ” ê¸°ë³¸ í…œí”Œë¦¿"""
    style_info = HOOK_STYLES[session.hook_style]
    intro_text = generate_intro_by_style(session)

    paper_highlights = []
    for paper in session.papers[:10]:
        if paper.get('abstract'):
            paper_highlights.append({
                'title': paper.get('title', ''),
                'abstract': paper.get('abstract', '')[:500],
                'journal': paper.get('journal', ''),
                'year': paper.get('year', '')
            })

    html = f'''<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{session.keyword} - ë¸”ë¡œê·¸</title>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{ font-family: 'Noto Sans KR', sans-serif; line-height: 1.8; color: #333; background: #fafafa; }}
        .hero {{ width: 100%; height: 280px; object-fit: cover; }}
        .container {{ max-width: 720px; margin: 0 auto; padding: 20px; background: white; }}
        .badge {{ display: inline-block; background: #e8f5e9; color: #2e7d32; padding: 4px 12px; border-radius: 20px; font-size: 0.85rem; margin-bottom: 12px; }}
        h1 {{ font-size: 1.8rem; line-height: 1.4; margin-bottom: 20px; }}
        h2 {{ font-size: 1.4rem; margin: 40px 0 20px; padding-bottom: 10px; border-bottom: 2px solid #4CAF50; }}
        p {{ margin-bottom: 18px; font-size: 1.05rem; }}
        .intro-box {{ background: linear-gradient(135deg, #e3f2fd 0%, #f3e5f5 100%); padding: 25px; border-radius: 12px; margin: 25px 0; }}
        .citation {{ background: #fff8e1; border-left: 4px solid #ffc107; padding: 20px; margin: 25px 0; font-style: italic; border-radius: 0 8px 8px 0; }}
        .highlight-box {{ background: #e8f5e9; border-radius: 12px; padding: 25px; margin: 25px 0; }}
        .highlight-box h4 {{ color: #2e7d32; margin-bottom: 15px; }}
        .highlight-box ul {{ margin-left: 20px; }}
        .highlight-box li {{ margin-bottom: 10px; }}
        .section-image {{ width: 100%; border-radius: 12px; margin: 25px 0; }}
        .references {{ background: #f5f5f5; padding: 25px; border-radius: 12px; margin-top: 40px; }}
        .references h4 {{ margin-bottom: 15px; color: #666; }}
        .references ul {{ font-size: 0.9rem; color: #666; margin-left: 20px; }}
        .references li {{ margin-bottom: 8px; }}
        .disclaimer {{ background: #eceff1; padding: 20px; border-radius: 8px; margin-top: 30px; font-size: 0.85rem; color: #666; }}
        .warning {{ background: #fff3e0; padding: 20px; border-radius: 8px; margin: 20px 0; border-left: 4px solid #ff9800; }}
    </style>
</head>
<body>
    <img src="https://images.unsplash.com/photo-1571019613454-1cb2f99b2d8b?w=1200&h=280&fit=crop" class="hero">

    <div class="container">
        <span class="badge">{len(session.papers)}í¸ ë…¼ë¬¸ ë¶„ì„</span>
        <h1>{session.keyword}, ë…¼ë¬¸ì´ ë§í•˜ëŠ” ì§„ì§œ ì´ì•¼ê¸°</h1>

        <div class="warning">
            <strong>âš ï¸ ì•ˆë‚´:</strong> Anthropic API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ê¸°ë³¸ í…œí”Œë¦¿ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
            .env íŒŒì¼ì— ANTHROPIC_API_KEYë¥¼ ì„¤ì •í•˜ë©´ AIê°€ ë…¼ë¬¸ì„ ë¶„ì„í•˜ì—¬ ë” í’ë¶€í•œ ê¸€ì„ ì‘ì„±í•©ë‹ˆë‹¤.
        </div>

        <div class="intro-box">
            {intro_text}
        </div>

        <h2>1. ì£¼ìš” ë°œê²¬</h2>
        <p>ì´ë²ˆ ë¶„ì„ì—ì„œëŠ” {', '.join(list(session.selected_topics)[:5])} ë“±ì˜ í† í”½ì„ ì¤‘ì‹¬ìœ¼ë¡œ {len(session.papers)}í¸ì˜ ë…¼ë¬¸ì„ ê²€í† í–ˆìŠµë‹ˆë‹¤.</p>

        <img src="https://images.unsplash.com/photo-1532938911079-1b06ac7ceec7?w=700&h=400&fit=crop" class="section-image">
'''

    for paper in paper_highlights[:3]:
        html += f'''
        <div class="citation">
            "{paper['abstract'][:300]}..."<br><br>
            â€” {paper['journal']}, {paper['year']}
        </div>
'''

    html += f'''
        <h2>2. í•µì‹¬ ì •ë¦¬</h2>
        <div class="highlight-box">
            <h4>ì´ ê¸€ì˜ í•µì‹¬</h4>
            <ul>
'''

    for topic in list(session.selected_topics)[:5]:
        html += f'                <li>{session.keyword}ê³¼ {topic}ì˜ ê´€ê³„ì— ëŒ€í•œ ìµœì‹  ì—°êµ¬ ê²°ê³¼</li>\n'

    html += '''            </ul>
        </div>

        <div class="references">
            <h4>ì°¸ê³  ë…¼ë¬¸</h4>
            <ul>
'''

    for paper in session.papers[:6]:
        html += f'                <li>{paper.get("title", "ì œëª© ì—†ìŒ")} ({paper.get("journal", "ì €ë„ ë¯¸ìƒ")}, {paper.get("year", "ì—°ë„ ë¯¸ìƒ")})</li>\n'

    if len(session.papers) > 6:
        html += f'                <li>ì™¸ {len(session.papers) - 6}í¸</li>\n'

    html += '''            </ul>
        </div>

        <div class="disclaimer">
            <strong>ë©´ì±… ì¡°í•­:</strong> ì´ ê¸€ì€ ì˜í•™ ë…¼ë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ê±´ê°• ì •ë³´ ì œê³µ ëª©ì ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
            êµ¬ì²´ì ì¸ ì¹˜ë£Œ ê²°ì •ì€ ë°˜ë“œì‹œ ë‹´ë‹¹ ì˜ë£Œì§„ê³¼ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.
        </div>
    </div>
</body>
</html>'''

    return html


def generate_intro_by_style(session: BlogBotSession) -> str:
    """Hook ìŠ¤íƒ€ì¼ì— ë”°ë¥¸ ë„ì…ë¶€ ìƒì„±"""
    keyword = session.keyword
    topics = list(session.selected_topics)[:3]
    papers_count = len(session.papers)

    intros = {
        'stat_shock': f'''<p>{keyword} ê´€ë ¨ ë…¼ë¬¸ {papers_count}í¸ì„ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.
ê·¸ ì¤‘ ëˆˆì— ë„ëŠ” í†µê³„ê°€ ìˆì—ˆëŠ”ë°ìš”. ê¸°ì¡´ì— ì•Œë ¤ì§„ ê²ƒê³¼ ë‹¤ë¥¸ ê²°ê³¼ë“¤ì´ ê½¤ ìˆì—ˆìŠµë‹ˆë‹¤.
íŠ¹íˆ {topics[0] if topics else 'ìµœê·¼ ì—°êµ¬'}ì— ëŒ€í•œ ë‚´ìš©ì´ ì¸ìƒì ì´ì—ˆìŠµë‹ˆë‹¤.</p>''',

        'counterintuitive': f'''<p>{topics[0] if topics else keyword}, ì •ë§ ê·¸ë ‡ê²Œ ì¤‘ìš”í• ê¹Œìš”?
{papers_count}í¸ì˜ ë…¼ë¬¸ì„ ë¶„ì„í•´ë´¤ë”ë‹ˆ ì˜ì™¸ì˜ ë‹µì´ ë‚˜ì™”ìŠµë‹ˆë‹¤.
ê¸°ì¡´ ìƒì‹ê³¼ ë‹¤ë¥¸ ë¶€ë¶„ë“¤ì´ ê½¤ ìˆë”ë¼ê³ ìš”.</p>''',

        'reader_situation': f'''<p>í˜¹ì‹œ {keyword} ë•Œë¬¸ì— ê³ ë¯¼ì´ì‹ ê°€ìš”?
ì¸í„°ë„·ì—ì„œ ê²€ìƒ‰í•´ë´ë„ ë¹„ìŠ·í•œ ë§ë§Œ ë‚˜ì˜¤ê³ , ë­ê°€ ë§ëŠ”ì§€ í—·ê°ˆë¦¬ì…¨ì„ ê²ë‹ˆë‹¤.
ê·¸ë˜ì„œ ì´ë²ˆì— {papers_count}í¸ì˜ ë…¼ë¬¸ì„ ì§ì ‘ ë¶„ì„í•´ë´¤ìŠµë‹ˆë‹¤.</p>''',

        'news_trend': f'''<p>ìµœê·¼ {keyword}ì— ëŒ€í•œ ìƒˆë¡œìš´ ì—°êµ¬ ê²°ê³¼ë“¤ì´ ë°œí‘œë˜ê³  ìˆìŠµë‹ˆë‹¤.
{papers_count}í¸ì˜ ë…¼ë¬¸ì„ ë¶„ì„í•œ ê²°ê³¼, {topics[0] if topics else 'ì£¼ìš” ë°œê²¬'}ì— ëŒ€í•´
ê¸°ì¡´ê³¼ ë‹¤ë¥¸ ì‹œê°ì˜ ì—°êµ¬ë“¤ì´ ëˆˆì— ë„ì—ˆìŠµë‹ˆë‹¤.</p>''',

        'conversation': f'''<p>{keyword} ê²€ìƒ‰í•´ë³´ë©´ ë‹¤ ë¹„ìŠ·í•œ ë§ë§Œ ë‚˜ì˜¤ì£ ?
{topics[0] if topics else 'ê´€ë ¨ ì •ë³´'} ì–´ì©Œê³ , {topics[1] if len(topics) > 1 else 'ì´ê²ƒì €ê²ƒ'} ì–´ì©Œê³ .
ê·¼ë° ë…¼ë¬¸ì„ ì§ì ‘ ì°¾ì•„ë³´ë‹ˆê¹Œ ì¢€ ë‹¤ë¥¸ ì–˜ê¸°ë“¤ì´ ìˆë”ë¼ê³ ìš”.</p>''',

        'case_study': f'''<p>{keyword}ìœ¼ë¡œ ê³ ë¯¼í•˜ëŠ” ë¶„ë“¤ì´ ë§ìŠµë‹ˆë‹¤.
{papers_count}í¸ì˜ ì—°êµ¬ë¥¼ ë¶„ì„í•´ë³´ë‹ˆ, {topics[0] if topics else 'í•µì‹¬ ìš”ì¸'}ì´
ìƒê°ë³´ë‹¤ ì¤‘ìš”í•œ ì—­í• ì„ í•œë‹¤ëŠ” ê±¸ ì•Œ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.</p>''',

        'problem_direct': f'''<p>{keyword}. ê²€ìƒ‰í•˜ë©´ ëŠ˜ ê°™ì€ ì¡°ì–¸ë§Œ ë‚˜ì˜µë‹ˆë‹¤.
í•˜ì§€ë§Œ ê·¸ê²ƒë§Œìœ¼ë¡œ í•´ê²°ì´ ëìœ¼ë©´ ì§„ì‘ ë‚˜ì•˜ê² ì£ ?
{papers_count}í¸ì˜ ë…¼ë¬¸ì—ì„œ ì°¾ì€ ë‹¤ë¥¸ ì ‘ê·¼ë²•ì„ ì •ë¦¬í•´ë´¤ìŠµë‹ˆë‹¤.</p>''',

        'curiosity': f'''<p>{keyword}ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ê±´ ë­˜ê¹Œìš”?
{papers_count}í¸ì˜ ë…¼ë¬¸ì„ ë¶„ì„í•˜ê³  ë‚˜ì„œì•¼ ì•Œê²Œ ëœ ê²Œ ìˆìŠµë‹ˆë‹¤.
{topics[0] if topics else 'í•µì‹¬ ìš”ì†Œ'}ì— ëŒ€í•œ ì´ì•¼ê¸°ì¸ë°ìš”...</p>''',
    }

    return intros.get(session.hook_style, intros['reader_situation'])


async def cancel(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """ëŒ€í™” ì·¨ì†Œ"""
    await update.message.reply_text(
        "âŒ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.\n\n"
        "/start ë¡œ ë‹¤ì‹œ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )
    return ConversationHandler.END


async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """ë„ì›€ë§"""
    await update.message.reply_text(
        "ğŸ“– *ë¸”ë¡œê·¸ ìë™ ìƒì„± ë´‡ ì‚¬ìš©ë²•*\n\n"
        "1ï¸âƒ£ /start - ìƒˆ ë¸”ë¡œê·¸ ì‘ì„± ì‹œì‘\n"
        "2ï¸âƒ£ í‚¤ì›Œë“œ ì…ë ¥ (ì˜ˆ: ì—­ë¥˜ì„±ì‹ë„ì—¼)\n"
        "3ï¸âƒ£ ê´€ì‹¬ í† í”½ ë‹¤ì¤‘ ì„ íƒ\n"
        "4ï¸âƒ£ ë…¼ë¬¸ ê²€ìƒ‰ ê²°ê³¼ í™•ì¸\n"
        "5ï¸âƒ£ ë„ì…ë¶€ ìŠ¤íƒ€ì¼ ì„ íƒ\n"
        "6ï¸âƒ£ ë¸”ë¡œê·¸ ìƒì„± ë° ë‹¤ìš´ë¡œë“œ\n\n"
        "/retry - ì´ì „ ì„¸ì…˜ ì´ì–´ì„œ ì§„í–‰\n"
        "/cancel - ì§„í–‰ ì¤‘ì¸ ì‘ì—… ì·¨ì†Œ\n"
        "/help - ì´ ë„ì›€ë§ ë³´ê¸°",
        parse_mode='Markdown'
    )


async def retry_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """ì €ì¥ëœ ì„¸ì…˜ ëª©ë¡ í‘œì‹œ ë° ì¬ì‹œë„"""
    user_id = update.effective_user.id
    sessions = BlogBotSession.list_saved_sessions()

    if not sessions:
        await update.message.reply_text(
            "ğŸ“­ ì €ì¥ëœ ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.\n\n"
            "/start ë¡œ ìƒˆ ë¸”ë¡œê·¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”."
        )
        return ConversationHandler.END

    # ì„¸ì…˜ ëª©ë¡ ë²„íŠ¼ ìƒì„±
    keyboard = []
    for i, s in enumerate(sessions[:5]):  # ìµœëŒ€ 5ê°œ
        step_name = {
            '1_keyword_analyzed': 'í‚¤ì›Œë“œë¶„ì„',
            '2_papers_searched': 'ë…¼ë¬¸ê²€ìƒ‰ì™„ë£Œ',
            '3_style_selected': 'ìŠ¤íƒ€ì¼ì„ íƒ',
            '4_generation_started': 'ìƒì„±ì‹œì‘'
        }.get(s['step'], s['step'])

        keyboard.append([
            InlineKeyboardButton(
                f"ğŸ“„ {s['keyword']} ({step_name}, {s['papers_count']}í¸)",
                callback_data=f"retry:{i}"
            )
        ])

    keyboard.append([InlineKeyboardButton("âŒ ì·¨ì†Œ", callback_data="retry:CANCEL")])

    # ì„¸ì…˜ ëª©ë¡ì„ contextì— ì €ì¥
    context.user_data['retry_sessions'] = sessions[:5]

    await update.message.reply_text(
        "ğŸ“‚ *ì €ì¥ëœ ì„¸ì…˜ ëª©ë¡*\n\n"
        "ì´ì–´ì„œ ì§„í–‰í•  ì„¸ì…˜ì„ ì„ íƒí•˜ì„¸ìš”:",
        reply_markup=InlineKeyboardMarkup(keyboard),
        parse_mode='Markdown'
    )

    return SELECTING_RETRY


async def handle_retry_selection(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """ì¬ì‹œë„ ì„¸ì…˜ ì„ íƒ ì²˜ë¦¬"""
    query = update.callback_query
    await query.answer()

    user_id = update.effective_user.id
    data = query.data.replace("retry:", "")

    if data == "CANCEL":
        await query.edit_message_text("âŒ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.\n\n/start ë¡œ ìƒˆë¡œ ì‹œì‘í•˜ì„¸ìš”.")
        return ConversationHandler.END

    try:
        idx = int(data)
        sessions = context.user_data.get('retry_sessions', [])
        if idx >= len(sessions):
            await query.edit_message_text("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
            return ConversationHandler.END

        selected = sessions[idx]
        filepath = selected['filepath']

        # ì„¸ì…˜ ë¶ˆëŸ¬ì˜¤ê¸°
        session = BlogBotSession.load_from_file(filepath)
        user_sessions[user_id] = session

        step = selected['step']

        # ë‹¨ê³„ì— ë”°ë¼ ë‹¤ìŒ ì§„í–‰
        if step == '4_generation_started' or step == '3_style_selected':
            # ë¸”ë¡œê·¸ ìƒì„± ë°”ë¡œ ì§„í–‰
            await query.edit_message_text(
                f"âœ… *ì„¸ì…˜ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ!*\n\n"
                f"ğŸ“Œ í‚¤ì›Œë“œ: {session.keyword}\n"
                f"ğŸ“„ ë…¼ë¬¸: {len(session.papers)}í¸\n"
                f"ğŸ·ï¸ í† í”½: {len(session.selected_topics)}ê°œ\n\n"
                f"ë¸”ë¡œê·¸ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...",
                parse_mode='Markdown'
            )

            # ë¸”ë¡œê·¸ ìƒì„± ì‹œì‘
            return await _generate_blog_from_session(update, context, session)

        elif step == '2_papers_searched':
            # ìŠ¤íƒ€ì¼ ì„ íƒë¶€í„°
            await query.edit_message_text(
                f"âœ… *ì„¸ì…˜ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ!*\n\n"
                f"ğŸ“Œ í‚¤ì›Œë“œ: {session.keyword}\n"
                f"ğŸ“„ ë…¼ë¬¸: {len(session.papers)}í¸\n\n"
                f"ë„ì…ë¶€ ìŠ¤íƒ€ì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.",
                parse_mode='Markdown'
            )
            return await show_hook_styles(update, context)

        else:
            # ì²˜ìŒë¶€í„° (í† í”½ ì„ íƒ)
            await query.edit_message_text(
                f"âœ… *ì„¸ì…˜ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ!*\n\n"
                f"ğŸ“Œ í‚¤ì›Œë“œ: {session.keyword}\n\n"
                f"/start ë¡œ ë‹¤ì‹œ ì‹œì‘í•˜ê±°ë‚˜ ê³„ì† ì§„í–‰í•˜ì„¸ìš”."
            )
            return ConversationHandler.END

    except Exception as e:
        await query.edit_message_text(f"âŒ ì„¸ì…˜ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return ConversationHandler.END


async def _generate_blog_from_session(update: Update, context: ContextTypes.DEFAULT_TYPE, session: BlogBotSession) -> int:
    """ì„¸ì…˜ì—ì„œ ë¸”ë¡œê·¸ ìƒì„±"""
    chat_id = update.effective_chat.id

    # Hook ìŠ¤íƒ€ì¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (í‚¤ê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ìŠ¤íƒ€ì¼ ì‚¬ìš©)
    style_info = HOOK_STYLES.get(session.hook_style)
    if not style_info:
        # ì €ì¥ëœ ìŠ¤íƒ€ì¼ í‚¤ê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ìŠ¤íƒ€ì¼ ì‚¬ìš©
        first_key = list(HOOK_STYLES.keys())[0]
        style_info = HOOK_STYLES[first_key]
        session.hook_style = first_key

    # ë¡œë”© í‘œì‹œ ì‹œì‘
    loading = LoadingIndicator(
        context.bot,
        chat_id,
        "*ë…¼ë¬¸ ë¶„ì„ ë° ë¸”ë¡œê·¸ ìƒì„± ì¤‘...*\n(ì¬ì‹œë„)"
    )
    await loading.start()

    try:
        from concurrent.futures import ThreadPoolExecutor
        from modules.auto_blog_generator import generate_blog_auto, get_last_error_log

        session_data = {
            'keyword': session.keyword,
            'keyword_en': session.keyword_en,
            'topics': list(session.selected_topics),
            'hook_style': session.hook_style,
            'hook_style_name': style_info['name'],
            'hook_style_desc': style_info['desc'],
            'hook_style_template': style_info.get('template', ''),
            'papers': session.papers
        }

        loop = asyncio.get_event_loop()
        with ThreadPoolExecutor() as executor:
            html_path = await loop.run_in_executor(
                executor,
                generate_blog_auto,
                session_data,
                "output"
            )

        await loading.delete()

        if html_path:
            await context.bot.send_message(
                chat_id=chat_id,
                text=f"âœ… *ë¸”ë¡œê·¸ ìƒì„± ì™„ë£Œ!*\n\nğŸ“„ íŒŒì¼: `{html_path}`",
                parse_mode='Markdown'
            )

            # íŒŒì¼ ì „ì†¡
            with open(html_path, 'rb') as f:
                await context.bot.send_document(
                    chat_id=chat_id,
                    document=f,
                    filename=os.path.basename(html_path)
                )
        else:
            error_logs = get_last_error_log()
            error_text = "\n".join(error_logs[-10:]) if error_logs else "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"
            await context.bot.send_message(
                chat_id=chat_id,
                text=f"âŒ *ë¸”ë¡œê·¸ ìƒì„± ì‹¤íŒ¨*\n\n```\n{error_text[:1500]}\n```",
                parse_mode='Markdown'
            )

    except Exception as e:
        await loading.delete()
        await context.bot.send_message(
            chat_id=chat_id,
            text=f"âŒ ì˜¤ë¥˜: {e}"
        )

    return ConversationHandler.END


# ì¬ì‹œë„ ìƒíƒœ ì¶”ê°€
SELECTING_RETRY = 99


def main():
    """ë´‡ ì‹¤í–‰"""
    # Configì—ì„œ í† í° ê°€ì ¸ì˜¤ê¸° (dotenv ìë™ ë¡œë“œ)
    token = Config.TELEGRAM_BOT_TOKEN

    if not token:
        print("âŒ TELEGRAM_BOT_TOKENì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   .env íŒŒì¼ì— TELEGRAM_BOT_TOKEN=your_token ì„ ì¶”ê°€í•˜ì„¸ìš”.")
        print("   í† í°ì€ @BotFather ì—ì„œ ë°œê¸‰ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return

    # ë´‡ ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±
    application = Application.builder().token(token).build()

    # ëŒ€í™” í•¸ë“¤ëŸ¬ ì„¤ì •
    conv_handler = ConversationHandler(
        entry_points=[
            CommandHandler("start", start),
            CommandHandler("retry", retry_command),
        ],
        states={
            WAITING_KEYWORD: [
                MessageHandler(filters.TEXT & ~filters.COMMAND, receive_keyword)
            ],
            SELECTING_TOPICS: [
                CallbackQueryHandler(toggle_topic, pattern="^topic:")
            ],
            SEARCHING_PAPERS: [
                CallbackQueryHandler(handle_paper_result, pattern="^papers:")
            ],
            SELECTING_HOOK_STYLE: [
                CallbackQueryHandler(select_hook_style, pattern="^hook:")
            ],
            CONFIRMING_DRAFT: [
                CallbackQueryHandler(confirm_generation, pattern="^confirm:")
            ],
            SELECTING_RETRY: [
                CallbackQueryHandler(handle_retry_selection, pattern="^retry:")
            ],
        },
        fallbacks=[CommandHandler("cancel", cancel)],
    )

    application.add_handler(conv_handler)
    application.add_handler(CommandHandler("help", help_command))

    # ë´‡ ì‹¤í–‰
    print("ğŸ¤– ë¸”ë¡œê·¸ ìƒì„± ë´‡ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("   Ctrl+C ë¡œ ì¢…ë£Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    application.run_polling(allowed_updates=Update.ALL_TYPES, drop_pending_updates=True)


if __name__ == "__main__":
    main()
